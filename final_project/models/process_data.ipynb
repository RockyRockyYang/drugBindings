{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0f9520ba11fdc1099356e05d27a34ed870b487e4078e45fe1cddd0198c8b5354c",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Dense, concatenate, Dropout\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import networkx as nx\n",
    "\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SMILES string:\n",
      "COc1cc2c(cc1Cl)C(c1ccc(Cl)c(Cl)c1)=NCC2\n",
      "\n",
      "Original molecule:\n",
      "<deepchem.feat.mol_graphs.ConvMol object at 0x7f8449ed9790>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=300x300 at 0x7F8469D99CA0>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Read in drugs and proteins\n",
    "drugs_ = json.load(open(LOCAL_KIBA_PATH), object_pairs_hook=OrderedDict)\n",
    "smiles = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(d),isomericSmiles=True) for d in drugs_.values()])\n",
    "\n",
    "print('SMILES string:')\n",
    "print(smiles[0])\n",
    "print('\\nOriginal molecule:')\n",
    "mols = MolFromSmiles(smiles[0])\n",
    "\n",
    "featurizer=dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "graph_data = featurizer.featurize(smiles)\n",
    "print(graph_data[0])\n",
    "Draw.MolToImage(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The codes in this cell are from section 10 of AM216\n",
    "\n",
    "LOCAL_KIBA_PATH = '../data/mini_project_data/data/kiba/'\n",
    "LOCAL_DAVIS_PATH = '../data/GraphDTA_davis/'\n",
    "G_PATH = './drive/MyDrive/Colab Notebooks/Drug Binding'\n",
    "def smiles_graph(path):\n",
    "    drugs_ = json.load(open(path + 'ligands_can.txt'), object_pairs_hook=OrderedDict)\n",
    "    smiles = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(d),isomericSmiles=True) for d in drugs_.values()])\n",
    "\n",
    "    # print('\\nOriginal molecule:')\n",
    "    mols = MolFromSmiles(smiles[0])\n",
    "    # Draw.MolToImage(mols)\n",
    "    featurizer=dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "    graph_data = featurizer.featurize(smiles)\n",
    "    return smiles, graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert SMILES to graphs\n",
    "smiles_kiba, convmol_kiba = smiles_graph(LOCAL_KIBA_PATH)\n",
    "smiles_davis, convmol_davis = smiles_graph(LOCAL_DAVIS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([<deepchem.feat.mol_graphs.ConvMol object at 0x7f845d8f07c0>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x7f845d8f0e50>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x7f845d8f03a0>, ...,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x7f844af50730>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x7f844af503a0>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x7f844af50dc0>],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "convmol_kiba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in affinity data\n",
    "affinity_kiba = np.array(pickle.load(open(LOCAL_KIBA_PATH + \"Y\",\"rb\"), encoding='latin1'))\n",
    "affinity_davis = np.array(pickle.load(open(LOCAL_DAVIS_PATH + \"Y\",\"rb\"), encoding='latin1'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train/test fold  \n",
    "train_fold = json.load(open(LOCAL_KIBA_PATH + \"folds/train_fold_setting1.txt\"))\n",
    "train_fold = [ee for e in train_fold for ee in e ]    \n",
    "test_fold = json.load(open(LOCAL_KIBA_PATH + \"folds/test_fold_setting1.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator to convert ConvMol to input for TF\n",
    "def data_generator(dataset):\n",
    "  for multiConvMol in graphs_kiba:\n",
    "    inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "      inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    labels = [np.array([1.0]*10 + [0.0]*11)]\n",
    "    weights = labels\n",
    "    yield (inputs, labels, weights)\n",
    "\n",
    "multiConvMol = graphs_davis[0]\n",
    "inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    inputs.append(multiConvMol.get_deg_adjacency_lists()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13 (21, 75) (21,) (21,)\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, weights = data_generator(graphs_kiba)\n",
    "print(len(inputs), inputs[0].shape, labels[0].shape, weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21, 75)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj2matr(raw_a):\n",
    "    len_a = len(raw_a)\n",
    "    matr = np.zeros((len_a, len_a))\n",
    "    for i in range(len_a):\n",
    "        for j in raw_a[i]:\n",
    "            matr[i, j] = 1\n",
    "    return sp.csr_matrix(matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convmol to matrices\n",
    "nodes_davis = []\n",
    "adj_davis = []\n",
    "for i in range(len(convmol_davis)):\n",
    "    nodes_davis.append(convmol_davis[i].get_atom_features())\n",
    "    adj_davis.append(adj2matr(convmol_davis[i].get_adjacency_list()))\n",
    "# nodes_davis = np.array(nodes_davis)\n",
    "# adj_davis = np.array(adj_davis)\n",
    "temp_y_davis = np.array([1]*30 + [0]*38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68 [[1. 0. 0. ... 0. 1. 0.]\n [1. 0. 0. ... 0. 1. 0.]\n [1. 0. 0. ... 0. 1. 0.]\n ...\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(len(graphs_davis), graphs_davis[0].get_atom_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-154-d7eaa99b5497>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  np.array(graphs_davis[0].get_adjacency_list())\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([list([8]), list([34]), list([11]), list([22]), list([17, 7]),\n",
       "       list([33, 17]), list([9, 27]), list([4, 20]), list([0, 21]),\n",
       "       list([22, 6]), list([30, 34]), list([29, 2]), list([13, 14]),\n",
       "       list([25, 12]), list([12, 15]), list([14, 23]), list([21, 30]),\n",
       "       list([5, 4]), list([31, 19, 28]), list([18, 24, 32]),\n",
       "       list([7, 32, 33]), list([8, 16, 29]), list([26, 3, 9]),\n",
       "       list([15, 31, 25]), list([34, 33, 19]), list([28, 13, 23]),\n",
       "       list([27, 28, 22]), list([32, 26, 6]), list([26, 25, 18]),\n",
       "       list([34, 11, 21]), list([16, 10, 31]), list([23, 18, 30]),\n",
       "       list([20, 27, 19]), list([24, 5, 20]), list([10, 1, 29, 24])],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "np.array(graphs_davis[0].get_adjacency_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68 [[8], [34], [11], [22], [17, 7], [33, 17], [9, 27], [4, 20], [0, 21], [22, 6], [30, 34], [29, 2], [13, 14], [25, 12], [12, 15], [14, 23], [21, 30], [5, 4], [31, 19, 28], [18, 24, 32], [7, 32, 33], [8, 16, 29], [26, 3, 9], [15, 31, 25], [34, 33, 19], [28, 13, 23], [27, 28, 22], [32, 26, 6], [26, 25, 18], [34, 11, 21], [16, 10, 31], [23, 18, 30], [20, 27, 19], [24, 5, 20], [10, 1, 29, 24]]\n"
     ]
    }
   ],
   "source": [
    "print(len(graphs_davis), graphs_davis[0].get_adjacency_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from spektral.data import Dataset, DisjointLoader, Graph\n",
    "import scipy.sparse as sp\n",
    "\n",
    "class MyFirstGNN(Model):\n",
    "\n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense = Dense(n_labels, 'softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.graph_conv(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dense(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graphs_davis = [Graph(x=x, a=a, y=y) for x, a, y in zip(nodes_davis, adj_davis, temp_y_davis)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<spektral.data.loaders.BatchLoader at 0x7f846a948be0>"
      ]
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "source": [
    "from spektral.data import BatchLoader\n",
    "\n",
    "loader = BatchLoader(graphs_davis, batch_size=32)\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "StopIteration",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-a61ab353d918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyFirstGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L2Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spektral/data/loaders.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mnxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MyFirstGNN(32, 2)\n",
    "model.compile('adam', 'L2Loss')\n",
    "model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Define a Graph Convolution Model\n",
    "class MyGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MyGraphConvModel, self).__init__()\n",
    "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(256, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    # self.readout = GraphGather(batch_size=batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(8)\n",
    "    # self.logits = layers.Reshape((n_tasks, 2))\n",
    "    self.dense = layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    gc1_output = self.gc1(inputs)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + inputs[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + inputs[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + inputs[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    batch_norm3_output = self.dense2(batch_norm3_output)\n",
    "    # readout_output = self.readout([batch_norm3_output] + inputs[1:])\n",
    "\n",
    "    # logits_output = self.logits(self.dense2(batch_norm3_output))\n",
    "    return self.dense(batch_norm3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make apply the DeepChem wrapper \n",
    "model = dc.models.KerasModel(MyGraphConvModel(), loss=dc.models.losses.L2Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_11:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_10:0\", shape=(4, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_14:0\", shape=(18,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_13:0\", shape=(18, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_17:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_16:0\", shape=(24, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_11:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_10:0\", shape=(4, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_13:0\", shape=(18,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_12:0\", shape=(18, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_15:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_14:0\", shape=(24, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_17:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_16:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_11:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_10:0\", shape=(4, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_14:0\", shape=(18,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_13:0\", shape=(18, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_17:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_16:0\", shape=(24, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_11:0\", shape=(3,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_10:0\", shape=(3, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_14:0\", shape=(20,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_13:0\", shape=(20, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_17:0\", shape=(21,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Reshape_16:0\", shape=(21, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_11:0\", shape=(3,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_10:0\", shape=(3, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_13:0\", shape=(20,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_12:0\", shape=(20, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_15:0\", shape=(21,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Reshape_14:0\", shape=(21, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_11:0\", shape=(3,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_10:0\", shape=(3, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_14:0\", shape=(20,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_13:0\", shape=(20, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_17:0\", shape=(21,), dtype=int32), values=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Reshape_16:0\", shape=(21, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/my_graph_conv_model_6/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [20,1] vs. [21,1]\n\t [[node gradient_tape/sub/BroadcastGradientArgs (defined at /Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/deepchem/models/keras_model.py:474) ]] [Op:__inference_apply_gradient_for_batch_17485]\n\nFunction call stack:\napply_gradient_for_batch\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-39c00c77ef1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs_kiba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m       \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient_for_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [20,1] vs. [21,1]\n\t [[node gradient_tape/sub/BroadcastGradientArgs (defined at /Users/lihongzhang/opt/anaconda3/lib/python3.8/site-packages/deepchem/models/keras_model.py:474) ]] [Op:__inference_apply_gradient_for_batch_17485]\n\nFunction call stack:\napply_gradient_for_batch\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(data_generator(graphs_kiba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "RDKit WARNING: [17:45:38] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [17:45:55] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object DiskDataset._iterbatches_from_shards.<locals>.iterate at 0x7f84284f84a0>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "datasets[0].iterbatches(batch_size = 32, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}