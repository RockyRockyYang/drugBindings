{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Partly-Finished Drug_Binding_Miniproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN6dxHwuSFXW"
      },
      "source": [
        "# AM216 Mini-Project: Drug target interaction and COVID-19\n",
        "\n",
        "Rapid determination of whether a candidate small molecule will bind to a particular target receptor protein remains a stumbling block in drug discovery.  If you can find a small molecule that binds to a relevant protein and modifies its function, this molecule can serve as a drug.   This is an **inverse problem**: Given a protein, please find a small molecule that can bind to it.  \n",
        "\n",
        "One way of solving this inverse problem would be to use molecular dynamics: Create a molecular model of a protein. Create a molecular model of all possible small molecule drugs that can bind to the protein. Simulate the interactions between the small molecules and the proteins. Find the molecules that work.\n",
        "\n",
        "Or-you might be more mathematical and try to solve this as a straight-up optimization problem: Find the small molecule that optimally binds to the binding pocket of a given drug.\n",
        "\n",
        "Although conceptually appealing, this methodology is impossible: The major bottleneck is that we do not know and cannot accurately represent the interactions between small molecules and proteins.  The potentials are empirical with fitting parameters--they cannot be found from first principles and despite decades of work, we simply do not have good representations for them. For that reason, physical computation has been of limited utility for drug discovery.  \n",
        "\n",
        "We should mention that a secondary bottleneck is the computing power that would be required for this search -- but this is something that could be likely sorted out if it weren't for the first bottleneck.\n",
        "\n",
        "An alternative approach is to use a *data driven approach*. Instead of representing the physics, lets make a list of all known proteins and all small molecules that binds to each protein.  Lets then design a data driven way of associating small molecules to proteins, representing binding.  \n",
        "\n",
        "Note that for a data driven approach to succeed, the key step is to **find ways of representing the small molecule and the protein that make it possible to find the patterns in the existing datasets.**   Representation is the key problem.  Presumably, the best way to represent the proteins and the small molecules is to use the physics and biochemistry of what happens when binding occurs -- as by doing this, we will focus on features that are relevant.  Finding the right feature representations for this type of problem is a very active area of research.\n",
        "\n",
        "In this miniproject, you will dip your toe into the pond by studying a canonical problem, the binding affinity of small molecules against target proteins.  \n",
        "\n",
        "Given all that is happening in the world right now, it seems appropriate to assign you the additional mission is to use the trained model to identify drugs that could bind to the main protease$^*$ protein of COVID-19 and prevent the production of viral enzyme. \n",
        "\n",
        "To help you in this mission, you are given KIBA (\"Kinase Inhibitor Bioassay\") dataset which contains 2111 drugs and 229 proteins with total of 118254 drug-protein binding affinity scores. Those are stored in `ligands_can.txt`, `proteins.txt`, and `Y`, respectively. The rows of `Y` index drugs and the columns index proteins. The element of `Y` is a real-valued binding score that takes into account dissociation constant $K_d$, inhibition constant $K_i$, and half maximal inhibitory concentration $IC_{50}$. Refer to [original paper](https://pubs.acs.org/doi/pdf/10.1021/ci400709d) for more detail. We also provide splitted indices for 5-fold cross validation in `train_fold_setting.txt` and testset indices in `test_fold_setting.txt`. Lastly, `6Y84_A.fasta.txt` contains the amino acid sequence of COVID-19 protease.\n",
        "\n",
        "You will evalulate the performance of your model using MSE and Corcordance Index (CI), which is slightly relaxed metric that measures whether the predicted binding affinity val- ues of two random drug–target pairs were predicted in the same order as their true values were.\n",
        "\n",
        "*: Note that there are many other drug targets for COVID-19 virus. [This page](\n",
        "https://www.guidetopharmacology.org/coronavirus.jsp) gives you a good summary. \n",
        "\n",
        "To help you get started, we will first introduce you to Rdkit and DeepChem packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVhNjK4kSFXZ"
      },
      "source": [
        "## 1. Basic Cheminformatics with Rdkit and DeepChem\n",
        "\n",
        "For this project, you will most likely heavily rely on Rdkit and Deepchem. You can install DeepChem along with Rdkit following instruction [here](https://deepchem.io). If you are using Colab, run the following code block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7fQCZJ8q9Je",
        "outputId": "c7b4ee1a-864d-406f-b7a5-6a3975ea9b76"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKxF-cawScZK",
        "outputId": "5dca97f4-c088-4047-e7e6-8e4a592bfb47"
      },
      "source": [
        "# This may take a few minutes to run!\n",
        "!wget -c https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
        "!chmod +x Anaconda3-2019.10-Linux-x86_64.sh\n",
        "!bash ./Anaconda3-2019.10-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -y -c deepchem -c rdkit -c conda-forge -c omnia deepchem-gpu=2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 02:09:33--  https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 530308481 (506M) [application/x-sh]\n",
            "Saving to: ‘Anaconda3-2019.10-Linux-x86_64.sh’\n",
            "\n",
            "Anaconda3-2019.10-L 100%[===================>] 505.74M   162MB/s    in 3.1s    \n",
            "\n",
            "2021-04-26 02:09:37 (162 MB/s) - ‘Anaconda3-2019.10-Linux-x86_64.sh’ saved [530308481/530308481]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _ipyw_jlab_nb_ext_conf==0.1.0=py37_0\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - alabaster==0.7.12=py37_0\n",
            "    - anaconda-client==1.7.2=py37_0\n",
            "    - anaconda-navigator==1.9.7=py37_0\n",
            "    - anaconda-project==0.8.3=py_0\n",
            "    - anaconda==2019.10=py37_0\n",
            "    - asn1crypto==1.0.1=py37_0\n",
            "    - astroid==2.3.1=py37_0\n",
            "    - astropy==3.2.2=py37h7b6447c_0\n",
            "    - atomicwrites==1.3.0=py37_1\n",
            "    - attrs==19.2.0=py_0\n",
            "    - babel==2.7.0=py_0\n",
            "    - backcall==0.1.0=py37_0\n",
            "    - backports.functools_lru_cache==1.5=py_2\n",
            "    - backports.os==0.1.1=py37_0\n",
            "    - backports.shutil_get_terminal_size==1.0.0=py37_2\n",
            "    - backports.tempfile==1.0=py_1\n",
            "    - backports.weakref==1.0.post1=py_1\n",
            "    - backports==1.0=py_2\n",
            "    - beautifulsoup4==4.8.0=py37_0\n",
            "    - bitarray==1.0.1=py37h7b6447c_0\n",
            "    - bkcharts==0.2=py37_0\n",
            "    - blas==1.0=mkl\n",
            "    - bleach==3.1.0=py37_0\n",
            "    - blosc==1.16.3=hd408876_0\n",
            "    - bokeh==1.3.4=py37_0\n",
            "    - boto==2.49.0=py37_0\n",
            "    - bottleneck==1.2.1=py37h035aef0_1\n",
            "    - bzip2==1.0.8=h7b6447c_0\n",
            "    - ca-certificates==2019.8.28=0\n",
            "    - cairo==1.14.12=h8948797_3\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.12.3=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - click==7.0=py37_0\n",
            "    - cloudpickle==1.2.2=py_0\n",
            "    - clyent==1.2.2=py37_1\n",
            "    - colorama==0.4.1=py37_0\n",
            "    - conda-build==3.18.9=py37_3\n",
            "    - conda-env==2.6.0=1\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda-verify==3.4.2=py_1\n",
            "    - conda==4.7.12=py37_0\n",
            "    - contextlib2==0.6.0=py_0\n",
            "    - cryptography==2.7=py37h1ba5d50_0\n",
            "    - curl==7.65.3=hbc83047_0\n",
            "    - cycler==0.10.0=py37_0\n",
            "    - cython==0.29.13=py37he6710b0_0\n",
            "    - cytoolz==0.10.0=py37h7b6447c_0\n",
            "    - dask-core==2.5.2=py_0\n",
            "    - dask==2.5.2=py_0\n",
            "    - dbus==1.13.6=h746ee38_0\n",
            "    - decorator==4.4.0=py37_1\n",
            "    - defusedxml==0.6.0=py_0\n",
            "    - distributed==2.5.2=py_0\n",
            "    - docutils==0.15.2=py37_0\n",
            "    - entrypoints==0.3=py37_0\n",
            "    - et_xmlfile==1.0.1=py37_0\n",
            "    - expat==2.2.6=he6710b0_0\n",
            "    - fastcache==1.1.0=py37h7b6447c_0\n",
            "    - filelock==3.0.12=py_0\n",
            "    - flask==1.1.1=py_0\n",
            "    - fontconfig==2.13.0=h9420a91_0\n",
            "    - freetype==2.9.1=h8a8886c_1\n",
            "    - fribidi==1.0.5=h7b6447c_0\n",
            "    - fsspec==0.5.2=py_0\n",
            "    - future==0.17.1=py37_0\n",
            "    - get_terminal_size==1.0.0=haa9412d_0\n",
            "    - gevent==1.4.0=py37h7b6447c_0\n",
            "    - glib==2.56.2=hd408876_0\n",
            "    - glob2==0.7=py_0\n",
            "    - gmp==6.1.2=h6c8ec71_1\n",
            "    - gmpy2==2.0.8=py37h10f8cd9_2\n",
            "    - graphite2==1.3.13=h23475e2_0\n",
            "    - greenlet==0.4.15=py37h7b6447c_0\n",
            "    - gst-plugins-base==1.14.0=hbbd80ab_1\n",
            "    - gstreamer==1.14.0=hb453b48_1\n",
            "    - h5py==2.9.0=py37h7918eee_0\n",
            "    - harfbuzz==1.8.8=hffaf4a1_0\n",
            "    - hdf5==1.10.4=hb1b8bf9_0\n",
            "    - heapdict==1.0.1=py_0\n",
            "    - html5lib==1.0.1=py37_0\n",
            "    - icu==58.2=h9c2bf20_1\n",
            "    - idna==2.8=py37_0\n",
            "    - imageio==2.6.0=py37_0\n",
            "    - imagesize==1.1.0=py37_0\n",
            "    - importlib_metadata==0.23=py37_0\n",
            "    - intel-openmp==2019.4=243\n",
            "    - ipykernel==5.1.2=py37h39e3cac_0\n",
            "    - ipython==7.8.0=py37h39e3cac_0\n",
            "    - ipython_genutils==0.2.0=py37_0\n",
            "    - ipywidgets==7.5.1=py_0\n",
            "    - isort==4.3.21=py37_0\n",
            "    - itsdangerous==1.1.0=py37_0\n",
            "    - jbig==2.1=hdba287a_0\n",
            "    - jdcal==1.4.1=py_0\n",
            "    - jedi==0.15.1=py37_0\n",
            "    - jeepney==0.4.1=py_0\n",
            "    - jinja2==2.10.3=py_0\n",
            "    - joblib==0.13.2=py37_0\n",
            "    - jpeg==9b=h024ee3a_2\n",
            "    - json5==0.8.5=py_0\n",
            "    - jsonschema==3.0.2=py37_0\n",
            "    - jupyter==1.0.0=py37_7\n",
            "    - jupyter_client==5.3.3=py37_1\n",
            "    - jupyter_console==6.0.0=py37_0\n",
            "    - jupyter_core==4.5.0=py_0\n",
            "    - jupyterlab==1.1.4=pyhf63ae98_0\n",
            "    - jupyterlab_server==1.0.6=py_0\n",
            "    - keyring==18.0.0=py37_0\n",
            "    - kiwisolver==1.1.0=py37he6710b0_0\n",
            "    - krb5==1.16.1=h173b8e3_7\n",
            "    - lazy-object-proxy==1.4.2=py37h7b6447c_0\n",
            "    - libarchive==3.3.3=h5d8350f_5\n",
            "    - libcurl==7.65.3=h20c2e04_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libgfortran-ng==7.3.0=hdf63c60_0\n",
            "    - liblief==0.9.0=h7725739_2\n",
            "    - libpng==1.6.37=hbc83047_0\n",
            "    - libsodium==1.0.16=h1bed415_0\n",
            "    - libssh2==1.8.2=h1ba5d50_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - libtiff==4.0.10=h2733197_2\n",
            "    - libtool==2.4.6=h7b6447c_5\n",
            "    - libuuid==1.0.3=h1bed415_2\n",
            "    - libxcb==1.13=h1bed415_1\n",
            "    - libxml2==2.9.9=hea5a465_1\n",
            "    - libxslt==1.1.33=h7d1a2b0_0\n",
            "    - llvmlite==0.29.0=py37hd408876_0\n",
            "    - locket==0.2.0=py37_1\n",
            "    - lxml==4.4.1=py37hefd8a0e_0\n",
            "    - lz4-c==1.8.1.2=h14c3975_0\n",
            "    - lzo==2.10=h49e0be7_2\n",
            "    - markupsafe==1.1.1=py37h7b6447c_0\n",
            "    - matplotlib==3.1.1=py37h5429711_0\n",
            "    - mccabe==0.6.1=py37_1\n",
            "    - mistune==0.8.4=py37h7b6447c_0\n",
            "    - mkl-service==2.3.0=py37he904b0f_0\n",
            "    - mkl==2019.4=243\n",
            "    - mkl_fft==1.0.14=py37ha843d7b_0\n",
            "    - mkl_random==1.1.0=py37hd6b4f25_0\n",
            "    - mock==3.0.5=py37_0\n",
            "    - more-itertools==7.2.0=py37_0\n",
            "    - mpc==1.1.0=h10f8cd9_1\n",
            "    - mpfr==4.0.1=hdf1c602_3\n",
            "    - mpmath==1.1.0=py37_0\n",
            "    - msgpack-python==0.6.1=py37hfd86e86_1\n",
            "    - multipledispatch==0.6.0=py37_0\n",
            "    - navigator-updater==0.2.1=py37_0\n",
            "    - nbconvert==5.6.0=py37_1\n",
            "    - nbformat==4.4.0=py37_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - networkx==2.3=py_0\n",
            "    - nltk==3.4.5=py37_0\n",
            "    - nose==1.3.7=py37_2\n",
            "    - notebook==6.0.1=py37_0\n",
            "    - numba==0.45.1=py37h962f231_0\n",
            "    - numexpr==2.7.0=py37h9e4a6bb_0\n",
            "    - numpy-base==1.17.2=py37hde5b4d6_0\n",
            "    - numpy==1.17.2=py37haad9e8e_0\n",
            "    - numpydoc==0.9.1=py_0\n",
            "    - olefile==0.46=py37_0\n",
            "    - openpyxl==3.0.0=py_0\n",
            "    - openssl==1.1.1d=h7b6447c_2\n",
            "    - packaging==19.2=py_0\n",
            "    - pandas==0.25.1=py37he6710b0_0\n",
            "    - pandoc==2.2.3.2=0\n",
            "    - pandocfilters==1.4.2=py37_1\n",
            "    - pango==1.42.4=h049681c_0\n",
            "    - parso==0.5.1=py_0\n",
            "    - partd==1.0.0=py_0\n",
            "    - patchelf==0.9=he6710b0_3\n",
            "    - path.py==12.0.1=py_0\n",
            "    - pathlib2==2.3.5=py37_0\n",
            "    - patsy==0.5.1=py37_0\n",
            "    - pcre==8.43=he6710b0_0\n",
            "    - pep8==1.7.1=py37_0\n",
            "    - pexpect==4.7.0=py37_0\n",
            "    - pickleshare==0.7.5=py37_0\n",
            "    - pillow==6.2.0=py37h34e0f95_0\n",
            "    - pip==19.2.3=py37_0\n",
            "    - pixman==0.38.0=h7b6447c_0\n",
            "    - pkginfo==1.5.0.1=py37_0\n",
            "    - pluggy==0.13.0=py37_0\n",
            "    - ply==3.11=py37_0\n",
            "    - prometheus_client==0.7.1=py_0\n",
            "    - prompt_toolkit==2.0.10=py_0\n",
            "    - psutil==5.6.3=py37h7b6447c_0\n",
            "    - ptyprocess==0.6.0=py37_0\n",
            "    - py-lief==0.9.0=py37h7725739_2\n",
            "    - py==1.8.0=py37_0\n",
            "    - pycodestyle==2.5.0=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pycrypto==2.6.1=py37h14c3975_9\n",
            "    - pycurl==7.43.0.3=py37h1ba5d50_0\n",
            "    - pyflakes==2.1.1=py37_0\n",
            "    - pygments==2.4.2=py_0\n",
            "    - pylint==2.4.2=py37_0\n",
            "    - pyodbc==4.0.27=py37he6710b0_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pyparsing==2.4.2=py_0\n",
            "    - pyqt==5.9.2=py37h05f1152_2\n",
            "    - pyrsistent==0.15.4=py37h7b6447c_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - pytables==3.5.2=py37h71ec239_1\n",
            "    - pytest-arraydiff==0.3=py37h39e3cac_0\n",
            "    - pytest-astropy==0.5.0=py37_0\n",
            "    - pytest-doctestplus==0.4.0=py_0\n",
            "    - pytest-openfiles==0.4.0=py_0\n",
            "    - pytest-remotedata==0.3.2=py37_0\n",
            "    - pytest==5.2.1=py37_0\n",
            "    - python-dateutil==2.8.0=py37_0\n",
            "    - python-libarchive-c==2.8=py37_13\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - pytz==2019.3=py_0\n",
            "    - pywavelets==1.0.3=py37hdd07704_1\n",
            "    - pyyaml==5.1.2=py37h7b6447c_0\n",
            "    - pyzmq==18.1.0=py37he6710b0_0\n",
            "    - qt==5.9.7=h5867ecd_1\n",
            "    - qtawesome==0.6.0=py_0\n",
            "    - qtconsole==4.5.5=py_0\n",
            "    - qtpy==1.9.0=py_0\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ripgrep==0.10.0=hc07d326_0\n",
            "    - rope==0.14.0=py_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - scikit-image==0.15.0=py37he6710b0_0\n",
            "    - scikit-learn==0.21.3=py37hd81dba3_0\n",
            "    - scipy==1.3.1=py37h7c811a0_0\n",
            "    - seaborn==0.9.0=py37_0\n",
            "    - secretstorage==3.1.1=py37_0\n",
            "    - send2trash==1.5.0=py37_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - simplegeneric==0.8.1=py37_2\n",
            "    - singledispatch==3.4.0.3=py37_0\n",
            "    - sip==4.19.8=py37hf484d3e_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - snappy==1.1.7=hbae5bb6_3\n",
            "    - snowballstemmer==2.0.0=py_0\n",
            "    - sortedcollections==1.1.2=py37_0\n",
            "    - sortedcontainers==2.1.0=py37_0\n",
            "    - soupsieve==1.9.3=py37_0\n",
            "    - sphinx==2.2.0=py_0\n",
            "    - sphinxcontrib-applehelp==1.0.1=py_0\n",
            "    - sphinxcontrib-devhelp==1.0.1=py_0\n",
            "    - sphinxcontrib-htmlhelp==1.0.2=py_0\n",
            "    - sphinxcontrib-jsmath==1.0.1=py_0\n",
            "    - sphinxcontrib-qthelp==1.0.2=py_0\n",
            "    - sphinxcontrib-serializinghtml==1.1.3=py_0\n",
            "    - sphinxcontrib-websupport==1.1.2=py_0\n",
            "    - sphinxcontrib==1.0=py37_1\n",
            "    - spyder-kernels==0.5.2=py37_0\n",
            "    - spyder==3.3.6=py37_0\n",
            "    - sqlalchemy==1.3.9=py37h7b6447c_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - statsmodels==0.10.1=py37hdd07704_0\n",
            "    - sympy==1.4=py37_0\n",
            "    - tbb==2019.4=hfd86e86_0\n",
            "    - tblib==1.4.0=py_0\n",
            "    - terminado==0.8.2=py37_0\n",
            "    - testpath==0.4.2=py37_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - toolz==0.10.0=py_0\n",
            "    - tornado==6.0.3=py37h7b6447c_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - traitlets==4.3.3=py37_0\n",
            "    - unicodecsv==0.14.1=py37_0\n",
            "    - unixodbc==2.3.7=h14c3975_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wcwidth==0.1.7=py37_0\n",
            "    - webencodings==0.5.1=py37_1\n",
            "    - werkzeug==0.16.0=py_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - widgetsnbextension==3.5.1=py37_0\n",
            "    - wrapt==1.11.2=py37h7b6447c_0\n",
            "    - wurlitzer==1.0.3=py37_0\n",
            "    - xlrd==1.2.0=py37_0\n",
            "    - xlsxwriter==1.2.1=py_0\n",
            "    - xlwt==1.3.0=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zeromq==4.3.1=he6710b0_3\n",
            "    - zict==1.0.0=py_0\n",
            "    - zipp==0.6.0=py_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "    - zstd==1.3.7=h0b5b093_0\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _ipyw_jlab_nb_ext~ pkgs/main/linux-64::_ipyw_jlab_nb_ext_conf-0.1.0-py37_0\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  alabaster          pkgs/main/linux-64::alabaster-0.7.12-py37_0\n",
            "  anaconda           pkgs/main/linux-64::anaconda-2019.10-py37_0\n",
            "  anaconda-client    pkgs/main/linux-64::anaconda-client-1.7.2-py37_0\n",
            "  anaconda-navigator pkgs/main/linux-64::anaconda-navigator-1.9.7-py37_0\n",
            "  anaconda-project   pkgs/main/noarch::anaconda-project-0.8.3-py_0\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.0.1-py37_0\n",
            "  astroid            pkgs/main/linux-64::astroid-2.3.1-py37_0\n",
            "  astropy            pkgs/main/linux-64::astropy-3.2.2-py37h7b6447c_0\n",
            "  atomicwrites       pkgs/main/linux-64::atomicwrites-1.3.0-py37_1\n",
            "  attrs              pkgs/main/noarch::attrs-19.2.0-py_0\n",
            "  babel              pkgs/main/noarch::babel-2.7.0-py_0\n",
            "  backcall           pkgs/main/linux-64::backcall-0.1.0-py37_0\n",
            "  backports          pkgs/main/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ pkgs/main/noarch::backports.functools_lru_cache-1.5-py_2\n",
            "  backports.os       pkgs/main/linux-64::backports.os-0.1.1-py37_0\n",
            "  backports.shutil_~ pkgs/main/linux-64::backports.shutil_get_terminal_size-1.0.0-py37_2\n",
            "  backports.tempfile pkgs/main/noarch::backports.tempfile-1.0-py_1\n",
            "  backports.weakref  pkgs/main/noarch::backports.weakref-1.0.post1-py_1\n",
            "  beautifulsoup4     pkgs/main/linux-64::beautifulsoup4-4.8.0-py37_0\n",
            "  bitarray           pkgs/main/linux-64::bitarray-1.0.1-py37h7b6447c_0\n",
            "  bkcharts           pkgs/main/linux-64::bkcharts-0.2-py37_0\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bleach             pkgs/main/linux-64::bleach-3.1.0-py37_0\n",
            "  blosc              pkgs/main/linux-64::blosc-1.16.3-hd408876_0\n",
            "  bokeh              pkgs/main/linux-64::bokeh-1.3.4-py37_0\n",
            "  boto               pkgs/main/linux-64::boto-2.49.0-py37_0\n",
            "  bottleneck         pkgs/main/linux-64::bottleneck-1.2.1-py37h035aef0_1\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.8.28-0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.12.3-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  click              pkgs/main/linux-64::click-7.0-py37_0\n",
            "  cloudpickle        pkgs/main/noarch::cloudpickle-1.2.2-py_0\n",
            "  clyent             pkgs/main/linux-64::clyent-1.2.2-py37_1\n",
            "  colorama           pkgs/main/linux-64::colorama-0.4.1-py37_0\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-build        pkgs/main/linux-64::conda-build-3.18.9-py37_3\n",
            "  conda-env          pkgs/main/linux-64::conda-env-2.6.0-1\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  conda-verify       pkgs/main/noarch::conda-verify-3.4.2-py_1\n",
            "  contextlib2        pkgs/main/noarch::contextlib2-0.6.0-py_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.7-py37h1ba5d50_0\n",
            "  curl               pkgs/main/linux-64::curl-7.65.3-hbc83047_0\n",
            "  cycler             pkgs/main/linux-64::cycler-0.10.0-py37_0\n",
            "  cython             pkgs/main/linux-64::cython-0.29.13-py37he6710b0_0\n",
            "  cytoolz            pkgs/main/linux-64::cytoolz-0.10.0-py37h7b6447c_0\n",
            "  dask               pkgs/main/noarch::dask-2.5.2-py_0\n",
            "  dask-core          pkgs/main/noarch::dask-core-2.5.2-py_0\n",
            "  dbus               pkgs/main/linux-64::dbus-1.13.6-h746ee38_0\n",
            "  decorator          pkgs/main/linux-64::decorator-4.4.0-py37_1\n",
            "  defusedxml         pkgs/main/noarch::defusedxml-0.6.0-py_0\n",
            "  distributed        pkgs/main/noarch::distributed-2.5.2-py_0\n",
            "  docutils           pkgs/main/linux-64::docutils-0.15.2-py37_0\n",
            "  entrypoints        pkgs/main/linux-64::entrypoints-0.3-py37_0\n",
            "  et_xmlfile         pkgs/main/linux-64::et_xmlfile-1.0.1-py37_0\n",
            "  expat              pkgs/main/linux-64::expat-2.2.6-he6710b0_0\n",
            "  fastcache          pkgs/main/linux-64::fastcache-1.1.0-py37h7b6447c_0\n",
            "  filelock           pkgs/main/noarch::filelock-3.0.12-py_0\n",
            "  flask              pkgs/main/noarch::flask-1.1.1-py_0\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.9.1-h8a8886c_1\n",
            "  fribidi            pkgs/main/linux-64::fribidi-1.0.5-h7b6447c_0\n",
            "  fsspec             pkgs/main/noarch::fsspec-0.5.2-py_0\n",
            "  future             pkgs/main/linux-64::future-0.17.1-py37_0\n",
            "  get_terminal_size  pkgs/main/linux-64::get_terminal_size-1.0.0-haa9412d_0\n",
            "  gevent             pkgs/main/linux-64::gevent-1.4.0-py37h7b6447c_0\n",
            "  glib               pkgs/main/linux-64::glib-2.56.2-hd408876_0\n",
            "  glob2              pkgs/main/noarch::glob2-0.7-py_0\n",
            "  gmp                pkgs/main/linux-64::gmp-6.1.2-h6c8ec71_1\n",
            "  gmpy2              pkgs/main/linux-64::gmpy2-2.0.8-py37h10f8cd9_2\n",
            "  graphite2          pkgs/main/linux-64::graphite2-1.3.13-h23475e2_0\n",
            "  greenlet           pkgs/main/linux-64::greenlet-0.4.15-py37h7b6447c_0\n",
            "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-hbbd80ab_1\n",
            "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-hb453b48_1\n",
            "  h5py               pkgs/main/linux-64::h5py-2.9.0-py37h7918eee_0\n",
            "  harfbuzz           pkgs/main/linux-64::harfbuzz-1.8.8-hffaf4a1_0\n",
            "  hdf5               pkgs/main/linux-64::hdf5-1.10.4-hb1b8bf9_0\n",
            "  heapdict           pkgs/main/noarch::heapdict-1.0.1-py_0\n",
            "  html5lib           pkgs/main/linux-64::html5lib-1.0.1-py37_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-h9c2bf20_1\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  imageio            pkgs/main/linux-64::imageio-2.6.0-py37_0\n",
            "  imagesize          pkgs/main/linux-64::imagesize-1.1.0-py37_0\n",
            "  importlib_metadata pkgs/main/linux-64::importlib_metadata-0.23-py37_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2019.4-243\n",
            "  ipykernel          pkgs/main/linux-64::ipykernel-5.1.2-py37h39e3cac_0\n",
            "  ipython            pkgs/main/linux-64::ipython-7.8.0-py37h39e3cac_0\n",
            "  ipython_genutils   pkgs/main/linux-64::ipython_genutils-0.2.0-py37_0\n",
            "  ipywidgets         pkgs/main/noarch::ipywidgets-7.5.1-py_0\n",
            "  isort              pkgs/main/linux-64::isort-4.3.21-py37_0\n",
            "  itsdangerous       pkgs/main/linux-64::itsdangerous-1.1.0-py37_0\n",
            "  jbig               pkgs/main/linux-64::jbig-2.1-hdba287a_0\n",
            "  jdcal              pkgs/main/noarch::jdcal-1.4.1-py_0\n",
            "  jedi               pkgs/main/linux-64::jedi-0.15.1-py37_0\n",
            "  jeepney            pkgs/main/noarch::jeepney-0.4.1-py_0\n",
            "  jinja2             pkgs/main/noarch::jinja2-2.10.3-py_0\n",
            "  joblib             pkgs/main/linux-64::joblib-0.13.2-py37_0\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  json5              pkgs/main/noarch::json5-0.8.5-py_0\n",
            "  jsonschema         pkgs/main/linux-64::jsonschema-3.0.2-py37_0\n",
            "  jupyter            pkgs/main/linux-64::jupyter-1.0.0-py37_7\n",
            "  jupyter_client     pkgs/main/linux-64::jupyter_client-5.3.3-py37_1\n",
            "  jupyter_console    pkgs/main/linux-64::jupyter_console-6.0.0-py37_0\n",
            "  jupyter_core       pkgs/main/noarch::jupyter_core-4.5.0-py_0\n",
            "  jupyterlab         pkgs/main/noarch::jupyterlab-1.1.4-pyhf63ae98_0\n",
            "  jupyterlab_server  pkgs/main/noarch::jupyterlab_server-1.0.6-py_0\n",
            "  keyring            pkgs/main/linux-64::keyring-18.0.0-py37_0\n",
            "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.1.0-py37he6710b0_0\n",
            "  krb5               pkgs/main/linux-64::krb5-1.16.1-h173b8e3_7\n",
            "  lazy-object-proxy  pkgs/main/linux-64::lazy-object-proxy-1.4.2-py37h7b6447c_0\n",
            "  libarchive         pkgs/main/linux-64::libarchive-3.3.3-h5d8350f_5\n",
            "  libcurl            pkgs/main/linux-64::libcurl-7.65.3-h20c2e04_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0\n",
            "  liblief            pkgs/main/linux-64::liblief-0.9.0-h7725739_2\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libsodium          pkgs/main/linux-64::libsodium-1.0.16-h1bed415_0\n",
            "  libssh2            pkgs/main/linux-64::libssh2-1.8.2-h1ba5d50_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.0.10-h2733197_2\n",
            "  libtool            pkgs/main/linux-64::libtool-2.4.6-h7b6447c_5\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.13-h1bed415_1\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.9-hea5a465_1\n",
            "  libxslt            pkgs/main/linux-64::libxslt-1.1.33-h7d1a2b0_0\n",
            "  llvmlite           pkgs/main/linux-64::llvmlite-0.29.0-py37hd408876_0\n",
            "  locket             pkgs/main/linux-64::locket-0.2.0-py37_1\n",
            "  lxml               pkgs/main/linux-64::lxml-4.4.1-py37hefd8a0e_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.8.1.2-h14c3975_0\n",
            "  lzo                pkgs/main/linux-64::lzo-2.10-h49e0be7_2\n",
            "  markupsafe         pkgs/main/linux-64::markupsafe-1.1.1-py37h7b6447c_0\n",
            "  matplotlib         pkgs/main/linux-64::matplotlib-3.1.1-py37h5429711_0\n",
            "  mccabe             pkgs/main/linux-64::mccabe-0.6.1-py37_1\n",
            "  mistune            pkgs/main/linux-64::mistune-0.8.4-py37h7b6447c_0\n",
            "  mkl                pkgs/main/linux-64::mkl-2019.4-243\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.14-py37ha843d7b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py37hd6b4f25_0\n",
            "  mock               pkgs/main/linux-64::mock-3.0.5-py37_0\n",
            "  more-itertools     pkgs/main/linux-64::more-itertools-7.2.0-py37_0\n",
            "  mpc                pkgs/main/linux-64::mpc-1.1.0-h10f8cd9_1\n",
            "  mpfr               pkgs/main/linux-64::mpfr-4.0.1-hdf1c602_3\n",
            "  mpmath             pkgs/main/linux-64::mpmath-1.1.0-py37_0\n",
            "  msgpack-python     pkgs/main/linux-64::msgpack-python-0.6.1-py37hfd86e86_1\n",
            "  multipledispatch   pkgs/main/linux-64::multipledispatch-0.6.0-py37_0\n",
            "  navigator-updater  pkgs/main/linux-64::navigator-updater-0.2.1-py37_0\n",
            "  nbconvert          pkgs/main/linux-64::nbconvert-5.6.0-py37_1\n",
            "  nbformat           pkgs/main/linux-64::nbformat-4.4.0-py37_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  networkx           pkgs/main/noarch::networkx-2.3-py_0\n",
            "  nltk               pkgs/main/linux-64::nltk-3.4.5-py37_0\n",
            "  nose               pkgs/main/linux-64::nose-1.3.7-py37_2\n",
            "  notebook           pkgs/main/linux-64::notebook-6.0.1-py37_0\n",
            "  numba              pkgs/main/linux-64::numba-0.45.1-py37h962f231_0\n",
            "  numexpr            pkgs/main/linux-64::numexpr-2.7.0-py37h9e4a6bb_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.17.2-py37haad9e8e_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.17.2-py37hde5b4d6_0\n",
            "  numpydoc           pkgs/main/noarch::numpydoc-0.9.1-py_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
            "  openpyxl           pkgs/main/noarch::openpyxl-3.0.0-py_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_2\n",
            "  packaging          pkgs/main/noarch::packaging-19.2-py_0\n",
            "  pandas             pkgs/main/linux-64::pandas-0.25.1-py37he6710b0_0\n",
            "  pandoc             pkgs/main/linux-64::pandoc-2.2.3.2-0\n",
            "  pandocfilters      pkgs/main/linux-64::pandocfilters-1.4.2-py37_1\n",
            "  pango              pkgs/main/linux-64::pango-1.42.4-h049681c_0\n",
            "  parso              pkgs/main/noarch::parso-0.5.1-py_0\n",
            "  partd              pkgs/main/noarch::partd-1.0.0-py_0\n",
            "  patchelf           pkgs/main/linux-64::patchelf-0.9-he6710b0_3\n",
            "  path.py            pkgs/main/noarch::path.py-12.0.1-py_0\n",
            "  pathlib2           pkgs/main/linux-64::pathlib2-2.3.5-py37_0\n",
            "  patsy              pkgs/main/linux-64::patsy-0.5.1-py37_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.43-he6710b0_0\n",
            "  pep8               pkgs/main/linux-64::pep8-1.7.1-py37_0\n",
            "  pexpect            pkgs/main/linux-64::pexpect-4.7.0-py37_0\n",
            "  pickleshare        pkgs/main/linux-64::pickleshare-0.7.5-py37_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.0-py37h34e0f95_0\n",
            "  pip                pkgs/main/linux-64::pip-19.2.3-py37_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.38.0-h7b6447c_0\n",
            "  pkginfo            pkgs/main/linux-64::pkginfo-1.5.0.1-py37_0\n",
            "  pluggy             pkgs/main/linux-64::pluggy-0.13.0-py37_0\n",
            "  ply                pkgs/main/linux-64::ply-3.11-py37_0\n",
            "  prometheus_client  pkgs/main/noarch::prometheus_client-0.7.1-py_0\n",
            "  prompt_toolkit     pkgs/main/noarch::prompt_toolkit-2.0.10-py_0\n",
            "  psutil             pkgs/main/linux-64::psutil-5.6.3-py37h7b6447c_0\n",
            "  ptyprocess         pkgs/main/linux-64::ptyprocess-0.6.0-py37_0\n",
            "  py                 pkgs/main/linux-64::py-1.8.0-py37_0\n",
            "  py-lief            pkgs/main/linux-64::py-lief-0.9.0-py37h7725739_2\n",
            "  pycodestyle        pkgs/main/linux-64::pycodestyle-2.5.0-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pycrypto           pkgs/main/linux-64::pycrypto-2.6.1-py37h14c3975_9\n",
            "  pycurl             pkgs/main/linux-64::pycurl-7.43.0.3-py37h1ba5d50_0\n",
            "  pyflakes           pkgs/main/linux-64::pyflakes-2.1.1-py37_0\n",
            "  pygments           pkgs/main/noarch::pygments-2.4.2-py_0\n",
            "  pylint             pkgs/main/linux-64::pylint-2.4.2-py37_0\n",
            "  pyodbc             pkgs/main/linux-64::pyodbc-4.0.27-py37he6710b0_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pyparsing          pkgs/main/noarch::pyparsing-2.4.2-py_0\n",
            "  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py37h05f1152_2\n",
            "  pyrsistent         pkgs/main/linux-64::pyrsistent-0.15.4-py37h7b6447c_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  pytables           pkgs/main/linux-64::pytables-3.5.2-py37h71ec239_1\n",
            "  pytest             pkgs/main/linux-64::pytest-5.2.1-py37_0\n",
            "  pytest-arraydiff   pkgs/main/linux-64::pytest-arraydiff-0.3-py37h39e3cac_0\n",
            "  pytest-astropy     pkgs/main/linux-64::pytest-astropy-0.5.0-py37_0\n",
            "  pytest-doctestplus pkgs/main/noarch::pytest-doctestplus-0.4.0-py_0\n",
            "  pytest-openfiles   pkgs/main/noarch::pytest-openfiles-0.4.0-py_0\n",
            "  pytest-remotedata  pkgs/main/linux-64::pytest-remotedata-0.3.2-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  python-dateutil    pkgs/main/linux-64::python-dateutil-2.8.0-py37_0\n",
            "  python-libarchive~ pkgs/main/linux-64::python-libarchive-c-2.8-py37_13\n",
            "  pytz               pkgs/main/noarch::pytz-2019.3-py_0\n",
            "  pywavelets         pkgs/main/linux-64::pywavelets-1.0.3-py37hdd07704_1\n",
            "  pyyaml             pkgs/main/linux-64::pyyaml-5.1.2-py37h7b6447c_0\n",
            "  pyzmq              pkgs/main/linux-64::pyzmq-18.1.0-py37he6710b0_0\n",
            "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1\n",
            "  qtawesome          pkgs/main/noarch::qtawesome-0.6.0-py_0\n",
            "  qtconsole          pkgs/main/noarch::qtconsole-4.5.5-py_0\n",
            "  qtpy               pkgs/main/noarch::qtpy-1.9.0-py_0\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ripgrep            pkgs/main/linux-64::ripgrep-0.10.0-hc07d326_0\n",
            "  rope               pkgs/main/noarch::rope-0.14.0-py_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  scikit-image       pkgs/main/linux-64::scikit-image-0.15.0-py37he6710b0_0\n",
            "  scikit-learn       pkgs/main/linux-64::scikit-learn-0.21.3-py37hd81dba3_0\n",
            "  scipy              pkgs/main/linux-64::scipy-1.3.1-py37h7c811a0_0\n",
            "  seaborn            pkgs/main/linux-64::seaborn-0.9.0-py37_0\n",
            "  secretstorage      pkgs/main/linux-64::secretstorage-3.1.1-py37_0\n",
            "  send2trash         pkgs/main/linux-64::send2trash-1.5.0-py37_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  simplegeneric      pkgs/main/linux-64::simplegeneric-0.8.1-py37_2\n",
            "  singledispatch     pkgs/main/linux-64::singledispatch-3.4.0.3-py37_0\n",
            "  sip                pkgs/main/linux-64::sip-4.19.8-py37hf484d3e_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  snappy             pkgs/main/linux-64::snappy-1.1.7-hbae5bb6_3\n",
            "  snowballstemmer    pkgs/main/noarch::snowballstemmer-2.0.0-py_0\n",
            "  sortedcollections  pkgs/main/linux-64::sortedcollections-1.1.2-py37_0\n",
            "  sortedcontainers   pkgs/main/linux-64::sortedcontainers-2.1.0-py37_0\n",
            "  soupsieve          pkgs/main/linux-64::soupsieve-1.9.3-py37_0\n",
            "  sphinx             pkgs/main/noarch::sphinx-2.2.0-py_0\n",
            "  sphinxcontrib      pkgs/main/linux-64::sphinxcontrib-1.0-py37_1\n",
            "  sphinxcontrib-app~ pkgs/main/noarch::sphinxcontrib-applehelp-1.0.1-py_0\n",
            "  sphinxcontrib-dev~ pkgs/main/noarch::sphinxcontrib-devhelp-1.0.1-py_0\n",
            "  sphinxcontrib-htm~ pkgs/main/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
            "  sphinxcontrib-jsm~ pkgs/main/noarch::sphinxcontrib-jsmath-1.0.1-py_0\n",
            "  sphinxcontrib-qth~ pkgs/main/noarch::sphinxcontrib-qthelp-1.0.2-py_0\n",
            "  sphinxcontrib-ser~ pkgs/main/noarch::sphinxcontrib-serializinghtml-1.1.3-py_0\n",
            "  sphinxcontrib-web~ pkgs/main/noarch::sphinxcontrib-websupport-1.1.2-py_0\n",
            "  spyder             pkgs/main/linux-64::spyder-3.3.6-py37_0\n",
            "  spyder-kernels     pkgs/main/linux-64::spyder-kernels-0.5.2-py37_0\n",
            "  sqlalchemy         pkgs/main/linux-64::sqlalchemy-1.3.9-py37h7b6447c_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  statsmodels        pkgs/main/linux-64::statsmodels-0.10.1-py37hdd07704_0\n",
            "  sympy              pkgs/main/linux-64::sympy-1.4-py37_0\n",
            "  tbb                pkgs/main/linux-64::tbb-2019.4-hfd86e86_0\n",
            "  tblib              pkgs/main/noarch::tblib-1.4.0-py_0\n",
            "  terminado          pkgs/main/linux-64::terminado-0.8.2-py37_0\n",
            "  testpath           pkgs/main/linux-64::testpath-0.4.2-py37_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  toolz              pkgs/main/noarch::toolz-0.10.0-py_0\n",
            "  tornado            pkgs/main/linux-64::tornado-6.0.3-py37h7b6447c_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py37_0\n",
            "  unicodecsv         pkgs/main/linux-64::unicodecsv-0.14.1-py37_0\n",
            "  unixodbc           pkgs/main/linux-64::unixodbc-2.3.7-h14c3975_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wcwidth            pkgs/main/linux-64::wcwidth-0.1.7-py37_0\n",
            "  webencodings       pkgs/main/linux-64::webencodings-0.5.1-py37_1\n",
            "  werkzeug           pkgs/main/noarch::werkzeug-0.16.0-py_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  widgetsnbextension pkgs/main/linux-64::widgetsnbextension-3.5.1-py37_0\n",
            "  wrapt              pkgs/main/linux-64::wrapt-1.11.2-py37h7b6447c_0\n",
            "  wurlitzer          pkgs/main/linux-64::wurlitzer-1.0.3-py37_0\n",
            "  xlrd               pkgs/main/linux-64::xlrd-1.2.0-py37_0\n",
            "  xlsxwriter         pkgs/main/noarch::xlsxwriter-1.2.1-py_0\n",
            "  xlwt               pkgs/main/linux-64::xlwt-1.3.0-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zeromq             pkgs/main/linux-64::zeromq-4.3.1-he6710b0_3\n",
            "  zict               pkgs/main/noarch::zict-1.0.0-py_0\n",
            "  zipp               pkgs/main/noarch::zipp-0.6.0-py_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "  zstd               pkgs/main/linux-64::zstd-1.3.7-h0b5b093_0\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Anaconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Anaconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.7.12\n",
            "  latest version: 4.10.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - deepchem-gpu=2.3.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
            "    _tflow_select-2.1.0        |              gpu           2 KB\n",
            "    absl-py-0.12.0             |     pyhd8ed1ab_0          96 KB  conda-forge\n",
            "    astor-0.8.1                |     pyh9f0ad1d_0          25 KB  conda-forge\n",
            "    astunparse-1.6.3           |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    c-ares-1.17.1              |       h36c2ea0_0         111 KB  conda-forge\n",
            "    certifi-2019.9.11          |           py37_0         147 KB  conda-forge\n",
            "    conda-4.10.1               |   py37h89c1867_0         3.1 MB  conda-forge\n",
            "    cudatoolkit-10.1.243       |       h6bb024c_0       347.4 MB\n",
            "    cudnn-7.6.5.32             |       hc0a50b0_1       250.7 MB  conda-forge\n",
            "    cupti-10.1.168             |                0         1.4 MB\n",
            "    deepchem-gpu-2.3.0         |           py37_0         2.1 MB  deepchem\n",
            "    fftw3f-3.3.4               |                2         1.2 MB  omnia\n",
            "    gast-0.4.0                 |     pyh9f0ad1d_0          12 KB  conda-forge\n",
            "    google-pasta-0.2.0         |     pyh8c360ce_0          42 KB  conda-forge\n",
            "    grpcio-1.23.0              |   py37hb0870dc_1         1.1 MB  conda-forge\n",
            "    importlib-metadata-4.0.1   |   py37h89c1867_0          30 KB  conda-forge\n",
            "    keras-applications-1.0.8   |             py_1          30 KB  conda-forge\n",
            "    keras-preprocessing-1.1.2  |     pyhd8ed1ab_0          34 KB  conda-forge\n",
            "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
            "    libprotobuf-3.13.0.1       |       h8b12597_0         2.3 MB  conda-forge\n",
            "    libxgboost-1.2.0           |       he1b5a44_0         3.1 MB  conda-forge\n",
            "    markdown-3.3.4             |     pyhd8ed1ab_0          67 KB  conda-forge\n",
            "    mdtraj-1.9.5               |   py37h113d463_0         1.7 MB  conda-forge\n",
            "    openmm-7.4.2               |py37_cuda101_rc_1        11.9 MB  omnia\n",
            "    pdbfixer-1.6               |             py_1         167 KB  omnia\n",
            "    protobuf-3.13.0.1          |   py37h745909e_1         704 KB  conda-forge\n",
            "    py-boost-1.67.0            |   py37h04863e7_4         278 KB\n",
            "    py-xgboost-1.2.0           |   py37hc8dfbb8_0         1.7 MB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    rdkit-2020.03.3.0          |   py37hc20afe1_1        24.8 MB  rdkit\n",
            "    simdna-0.4.2               |             py_0         627 KB  deepchem\n",
            "    tensorboard-1.14.0         |           py37_0         3.2 MB  conda-forge\n",
            "    tensorflow-1.14.0          |gpu_py37h74c33d7_0           4 KB\n",
            "    tensorflow-base-1.14.0     |gpu_py37he45bfe2_0       146.3 MB\n",
            "    tensorflow-estimator-1.14.0|   py37h5ca1d4c_0         645 KB  conda-forge\n",
            "    tensorflow-gpu-1.14.0      |       h0d30ee6_0           3 KB\n",
            "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
            "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
            "    xgboost-1.2.0              |   py37h3340039_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       817.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
            "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.1.0-gpu\n",
            "  absl-py            conda-forge/noarch::absl-py-0.12.0-pyhd8ed1ab_0\n",
            "  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\n",
            "  astunparse         conda-forge/noarch::astunparse-1.6.3-pyhd8ed1ab_0\n",
            "  c-ares             conda-forge/linux-64::c-ares-1.17.1-h36c2ea0_0\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.1.243-h6bb024c_0\n",
            "  cudnn              conda-forge/linux-64::cudnn-7.6.5.32-hc0a50b0_1\n",
            "  cupti              pkgs/main/linux-64::cupti-10.1.168-0\n",
            "  deepchem-gpu       deepchem/linux-64::deepchem-gpu-2.3.0-py37_0\n",
            "  fftw3f             omnia/linux-64::fftw3f-3.3.4-2\n",
            "  gast               conda-forge/noarch::gast-0.4.0-pyh9f0ad1d_0\n",
            "  google-pasta       conda-forge/noarch::google-pasta-0.2.0-pyh8c360ce_0\n",
            "  grpcio             conda-forge/linux-64::grpcio-1.23.0-py37hb0870dc_1\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.0.1-py37h89c1867_0\n",
            "  keras-applications conda-forge/noarch::keras-applications-1.0.8-py_1\n",
            "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.2-pyhd8ed1ab_0\n",
            "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.13.0.1-h8b12597_0\n",
            "  libxgboost         conda-forge/linux-64::libxgboost-1.2.0-he1b5a44_0\n",
            "  markdown           conda-forge/noarch::markdown-3.3.4-pyhd8ed1ab_0\n",
            "  mdtraj             conda-forge/linux-64::mdtraj-1.9.5-py37h113d463_0\n",
            "  openmm             omnia/linux-64::openmm-7.4.2-py37_cuda101_rc_1\n",
            "  pdbfixer           omnia/noarch::pdbfixer-1.6-py_1\n",
            "  protobuf           conda-forge/linux-64::protobuf-3.13.0.1-py37h745909e_1\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py37h04863e7_4\n",
            "  py-xgboost         conda-forge/linux-64::py-xgboost-1.2.0-py37hc8dfbb8_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.03.3.0-py37hc20afe1_1\n",
            "  simdna             deepchem/noarch::simdna-0.4.2-py_0\n",
            "  tensorboard        conda-forge/linux-64::tensorboard-1.14.0-py37_0\n",
            "  tensorflow         pkgs/main/linux-64::tensorflow-1.14.0-gpu_py37h74c33d7_0\n",
            "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-1.14.0-gpu_py37he45bfe2_0\n",
            "  tensorflow-estima~ conda-forge/linux-64::tensorflow-estimator-1.14.0-py37h5ca1d4c_0\n",
            "  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-1.14.0-h0d30ee6_0\n",
            "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
            "  xgboost            conda-forge/linux-64::xgboost-1.2.0-py37h3340039_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.10.1-py37h89c1867_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi                                         pkgs/main --> conda-forge\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "tensorflow-1.14.0    | 4 KB      | : 100% 1.0/1 [00:00<00:00,  9.02it/s]\n",
            "libprotobuf-3.13.0.1 | 2.3 MB    | : 100% 1.0/1 [00:00<00:00, 12.28s/it]                 \n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 19.57it/s]\n",
            "c-ares-1.17.1        | 111 KB    | : 100% 1.0/1 [00:00<00:00, 13.60it/s]\n",
            "cudatoolkit-10.1.243 | 347.4 MB  | : 100% 1.0/1 [00:11<00:00, 11.21s/it]               \n",
            "libboost-1.67.0      | 13.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.19s/it]              \n",
            "certifi-2019.9.11    | 147 KB    | : 100% 1.0/1 [00:00<00:00,  8.64it/s]\n",
            "mdtraj-1.9.5         | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.06it/s]\n",
            "conda-4.10.1         | 3.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.50s/it]\n",
            "grpcio-1.23.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.64it/s]\n",
            "_tflow_select-2.1.0  | 2 KB      | : 100% 1.0/1 [00:00<00:00,  7.08it/s]\n",
            "gast-0.4.0           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 20.82it/s]\n",
            "astunparse-1.6.3     | 15 KB     | : 100% 1.0/1 [00:00<00:00, 18.41it/s]\n",
            "keras-applications-1 | 30 KB     | : 100% 1.0/1 [00:00<00:00, 18.16it/s]\n",
            "simdna-0.4.2         | 627 KB    | : 100% 1.0/1 [00:00<00:00,  3.41it/s]\n",
            "cudnn-7.6.5.32       | 250.7 MB  | : 100% 1.0/1 [00:44<00:00, 44.54s/it]               \n",
            "astor-0.8.1          | 25 KB     | : 100% 1.0/1 [00:00<00:00, 14.63it/s]\n",
            "pdbfixer-1.6         | 167 KB    | : 100% 1.0/1 [00:00<00:00,  4.53it/s]\n",
            "tensorflow-base-1.14 | 146.3 MB  | : 100% 1.0/1 [00:10<00:00, 10.04s/it]               \n",
            "deepchem-gpu-2.3.0   | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.35it/s]\n",
            "tensorflow-gpu-1.14. | 3 KB      | : 100% 1.0/1 [00:00<00:00,  6.67it/s]\n",
            "libxgboost-1.2.0     | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.93it/s]                \n",
            "keras-preprocessing- | 34 KB     | : 100% 1.0/1 [00:00<00:00, 13.79it/s]\n",
            "markdown-3.3.4       | 67 KB     | : 100% 1.0/1 [00:00<00:00, 15.66it/s]\n",
            "importlib-metadata-4 | 30 KB     | : 100% 1.0/1 [00:00<00:00, 20.55it/s]\n",
            "absl-py-0.12.0       | 96 KB     | : 100% 1.0/1 [00:00<00:00, 11.86it/s]\n",
            "google-pasta-0.2.0   | 42 KB     | : 100% 1.0/1 [00:00<00:00, 13.90it/s]\n",
            "py-xgboost-1.2.0     | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.42it/s]\n",
            "protobuf-3.13.0.1    | 704 KB    | : 100% 1.0/1 [00:00<00:00,  3.03it/s]              \n",
            "_py-xgboost-mutex-2. | 8 KB      | : 100% 1.0/1 [00:00<00:00, 19.57it/s]\n",
            "py-boost-1.67.0      | 278 KB    | : 100% 1.0/1 [00:00<00:00,  6.20it/s]\n",
            "termcolor-1.1.0      | 6 KB      | : 100% 1.0/1 [00:00<00:00, 16.05it/s]\n",
            "typing_extensions-3. | 25 KB     | : 100% 1.0/1 [00:00<00:00, 12.89it/s]\n",
            "tensorboard-1.14.0   | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.79it/s]               \n",
            "rdkit-2020.03.3.0    | 24.8 MB   | : 100% 1.0/1 [00:05<00:00,  5.78s/it]\n",
            "cupti-10.1.168       | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  5.36it/s]\n",
            "fftw3f-3.3.4         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.77it/s]\n",
            "openmm-7.4.2         | 11.9 MB   | : 100% 1.0/1 [00:03<00:00,  3.71s/it]\n",
            "tensorflow-estimator | 645 KB    | : 100% 1.0/1 [00:00<00:00,  2.95it/s]\n",
            "xgboost-1.2.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 20.23it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| b'By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\\n  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\\n'\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps7x414nDcHu",
        "outputId": "984b6ff5-fc63-4b1a-9340-fb47e6ef0e9e"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import deepchem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygWxSzB9SFXm"
      },
      "source": [
        "Developing new medicine is a very time-consuming, labor-intensive, and expensive task which begins with rounds of screening process where researchers run some assays with thousands of molecules to identify potential drug candidates to go onto a clinical trial. The field of cheminformatics have been developed to help accelerate this process by performing laboratory experiments on computers. \n",
        "\n",
        "In order to this we need to find a way to represent a molecule so that we can train machine learning models on it.  As mentioned above, this is a critical step.   If we were doing physics we would want to represent the molecule in the most natural way to represent the physics. For example there are features of the molecules that *cause* it to bind to the protein in question -- there are specific interactions between the chemical groups of the molecule and the amino acids. From a physical perspective, identifying these features is the most important part of the problem and we would like the representation to emphasize these.\n",
        "\n",
        "But given that we don't have any idea what is happening, we need another approach. We somehow have to represent both molecules and proteins in a way so that we can train machine learning models on them to see if it is possible to associate them with each other.\n",
        "\n",
        "For small molecules, this is a classic problem. How do we take a molecule and represent it. There is a field that has addressed this called 'cheminformatics'.  \n",
        "\n",
        "A particularly simple method is for molecules are represented as text strings called SMILES (“Simplified Molecular-Input Line-Entry System”). Please refer to [this page](https://www.daylight.com/dayhtml/doc/theory/theory.smiles.html) for more explanantion. Here is an example SMILES string and the molecule it represents, which we obtain via `MolFromSmiles` function of Rdkit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8YkkNgGSFXo",
        "outputId": "b37c9fb6-bbe3-44fb-db49-0b58210c31a0"
      },
      "source": [
        "import numpy as np\n",
        "import rdkit\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem import AllChem as Chem\n",
        "from rdkit.Chem import MolFromSmiles\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Dense, concatenate, Dropout\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "b4sRfDxkSFXs",
        "scrolled": false,
        "outputId": "bb600cab-ad6b-44eb-95ce-51385721cc7e"
      },
      "source": [
        "smiles = []\n",
        "LOCAL_PATH = '../Drug Binding'\n",
        "G_PATH = './drive/MyDrive/Colab Notebooks/Drug Binding'\n",
        "with open(G_PATH + '/data_Drug_target_binding_affinity/Sample_Ligand_List.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        smiles.append(line[:-1])\n",
        "        \n",
        "print('SMILES string:')\n",
        "print(smiles[0])\n",
        "\n",
        "print('\\nOriginal molecule:')\n",
        "mols = MolFromSmiles(smiles[0])\n",
        "Draw.MolToImage(mols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMILES string:\n",
            "O[C@@H](CNC1CCN(CC1)c2ccc(CC3SC(=O)NC3=O)cc2)c4ccc(O)c(NS(=O)(=O)c5ccccc5)c4\n",
            "\n",
            "Original molecule:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x7FBEE1B32390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuh706D2SFXw"
      },
      "source": [
        "As you may have guessed, this SMILES string does not contain much of structural and chemical information present in the actual molecule representation. \n",
        "\n",
        "The smiles string is a string of symbols -- it is very different from the binding structure of the molecules.  One option that we have is to train machine learning models on the smiles strings directly.\n",
        "\n",
        "This has been found to not be the most effective way of proceeding. Another approach that people have thought of is to convert this to a \"chemical fingerprint\". This is a\n",
        " vector of 1's and 0's that captures the presence or absence of specific features, as determined by local arrangement of atoms in a molecule.  \n",
        "\n",
        "\n",
        "There are many algorithms that give you this finger print. One example is Extended-connectivity fingerprints (ECFP) scheme, which comes as `GetMorganFingerprintAsBitVec` in Rdkit. Here is an example of ECFP4. The number at the end refers to bond distances used for featurizing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNYhVaVaSFXy",
        "scrolled": true,
        "outputId": "c10b91f4-1e9b-4a2b-8ec7-34d542cdf925"
      },
      "source": [
        "print('ECFP4')\n",
        "molecule = MolFromSmiles(smiles[0])\n",
        "ECFP2 = Chem.GetMorganFingerprintAsBitVect(molecule, 2).ToBitString()\n",
        "ECFP2arr = np.array(list(map(int, ECFP2)))\n",
        "print(ECFP2arr[:20], '...')\n",
        "print(ECFP2arr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ECFP4\n",
            "[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] ...\n",
            "(2048,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLDF_gKMSFX5"
      },
      "source": [
        "Lots of Rdkit's featurization algorithms are ported in DeepChem. This is a deep learning for chemistry toolkit that was developed at Stanford.\n",
        "\n",
        "We can list the descriptors for molecules from RDKIT. Note that in addition to fingerprints, there are all sorts of purely chemical features, such as\n",
        "\n",
        "\n",
        "*   Number of Hydrogen acceptors\n",
        "*   Number of aromatic rings\n",
        "*   Number of radical electrons\n",
        "*   Number of rings in the molecule\n",
        "*   Partial charges\n",
        "\n",
        "\n",
        "And so forth.  When you are doing machine learning with complete ignorance of why the small molecule binds to something, you might as well be as general as you can be!!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy0vsVrBSFX7",
        "outputId": "8ba6a91a-ef2e-4e41-c263-a925ac734b3b"
      },
      "source": [
        "from deepchem.feat import RDKitDescriptors   \n",
        "\n",
        "for descriptor in RDKitDescriptors.allowedDescriptors:\n",
        "    print(descriptor)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MolLogP\n",
            "SMR_VSA3\n",
            "SlogP_VSA2\n",
            "Chi1v\n",
            "VSA_EState3\n",
            "NumHeteroatoms\n",
            "PEOE_VSA1\n",
            "EState_VSA3\n",
            "MinAbsPartialCharge\n",
            "ExactMolWt\n",
            "SlogP_VSA6\n",
            "VSA_EState8\n",
            "NumHAcceptors\n",
            "Chi2n\n",
            "MinEStateIndex\n",
            "NumAromaticRings\n",
            "LabuteASA\n",
            "PEOE_VSA5\n",
            "NumAliphaticHeterocycles\n",
            "PEOE_VSA4\n",
            "PEOE_VSA3\n",
            "NumHDonors\n",
            "PEOE_VSA13\n",
            "Kappa1\n",
            "NumSaturatedHeterocycles\n",
            "Chi3v\n",
            "SMR_VSA4\n",
            "MaxEStateIndex\n",
            "EState_VSA10\n",
            "SMR_VSA1\n",
            "SlogP_VSA11\n",
            "SlogP_VSA7\n",
            "VSA_EState2\n",
            "SMR_VSA6\n",
            "VSA_EState1\n",
            "SMR_VSA9\n",
            "PEOE_VSA12\n",
            "EState_VSA5\n",
            "MinPartialCharge\n",
            "SMR_VSA7\n",
            "SlogP_VSA1\n",
            "HallKierAlpha\n",
            "TPSA\n",
            "RingCount\n",
            "PEOE_VSA14\n",
            "VSA_EState10\n",
            "HeavyAtomMolWt\n",
            "Kappa2\n",
            "NOCount\n",
            "EState_VSA4\n",
            "Chi4v\n",
            "NumSaturatedRings\n",
            "PEOE_VSA2\n",
            "MaxAbsEStateIndex\n",
            "Chi2v\n",
            "PEOE_VSA6\n",
            "Chi4n\n",
            "MaxAbsPartialCharge\n",
            "SlogP_VSA5\n",
            "NHOHCount\n",
            "BertzCT\n",
            "MinAbsEStateIndex\n",
            "SMR_VSA10\n",
            "SlogP_VSA4\n",
            "Chi1n\n",
            "PEOE_VSA7\n",
            "EState_VSA2\n",
            "VSA_EState4\n",
            "Chi0v\n",
            "NumValenceElectrons\n",
            "NumAliphaticCarbocycles\n",
            "Kappa3\n",
            "Chi0n\n",
            "VSA_EState6\n",
            "PEOE_VSA8\n",
            "EState_VSA6\n",
            "NumRotatableBonds\n",
            "VSA_EState9\n",
            "SlogP_VSA9\n",
            "VSA_EState5\n",
            "Chi1\n",
            "PEOE_VSA9\n",
            "SMR_VSA5\n",
            "EState_VSA7\n",
            "EState_VSA8\n",
            "NumAromaticCarbocycles\n",
            "NumSaturatedCarbocycles\n",
            "EState_VSA11\n",
            "EState_VSA1\n",
            "PEOE_VSA10\n",
            "FractionCSP3\n",
            "SlogP_VSA3\n",
            "Chi3n\n",
            "MaxPartialCharge\n",
            "NumRadicalElectrons\n",
            "SMR_VSA8\n",
            "MolMR\n",
            "Chi0\n",
            "SlogP_VSA8\n",
            "Ipc\n",
            "HeavyAtomCount\n",
            "BalabanJ\n",
            "EState_VSA9\n",
            "SMR_VSA2\n",
            "MolWt\n",
            "NumAromaticHeterocycles\n",
            "PEOE_VSA11\n",
            "SlogP_VSA12\n",
            "VSA_EState7\n",
            "NumAliphaticRings\n",
            "SlogP_VSA10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazROs-xSFYA"
      },
      "source": [
        "Deepchem has also implemented a large number of different machine learning models to build models on top of these features. We can list this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOnVGtOgSFYB",
        "outputId": "9ec767d1-9aee-4a87-c170-56716bf6faac"
      },
      "source": [
        "dir(dc.models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ANIRegression',\n",
              " 'AtomicConvModel',\n",
              " 'BPSymmetryFunctionRegression',\n",
              " 'ChemCeption',\n",
              " 'DAGModel',\n",
              " 'DAGTensorGraph',\n",
              " 'DTNNModel',\n",
              " 'DTNNTensorGraph',\n",
              " 'GAN',\n",
              " 'GraphConvModel',\n",
              " 'GraphConvTensorGraph',\n",
              " 'IRV',\n",
              " 'KerasModel',\n",
              " 'MPNNModel',\n",
              " 'MPNNTensorGraph',\n",
              " 'Model',\n",
              " 'MultitaskClassifier',\n",
              " 'MultitaskFitTransformRegressor',\n",
              " 'MultitaskRegressor',\n",
              " 'OntologyModel',\n",
              " 'OntologyNode',\n",
              " 'ProgressiveMultitaskClassifier',\n",
              " 'ProgressiveMultitaskRegressor',\n",
              " 'RobustMultitaskClassifier',\n",
              " 'RobustMultitaskRegressor',\n",
              " 'ScScoreModel',\n",
              " 'SeqToSeq',\n",
              " 'SequenceDNN',\n",
              " 'Sequential',\n",
              " 'SingletaskToMultitask',\n",
              " 'SklearnModel',\n",
              " 'Smiles2Vec',\n",
              " 'TensorGraph',\n",
              " 'TensorflowMultitaskIRVClassifier',\n",
              " 'TextCNNModel',\n",
              " 'TextCNNTensorGraph',\n",
              " 'ValidationCallback',\n",
              " 'WGAN',\n",
              " 'WeaveModel',\n",
              " 'WeaveTensorGraph',\n",
              " 'XGBoostModel',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'atomic_conv',\n",
              " 'callbacks',\n",
              " 'chemnet_models',\n",
              " 'create_gene_ontology',\n",
              " 'division',\n",
              " 'fcnet',\n",
              " 'gan',\n",
              " 'graph_models',\n",
              " 'keras_model',\n",
              " 'layers',\n",
              " 'losses',\n",
              " 'models',\n",
              " 'multitask',\n",
              " 'optimizers',\n",
              " 'progressive_multitask',\n",
              " 'robust_multitask',\n",
              " 'scscore',\n",
              " 'seqtoseq',\n",
              " 'sklearn_models',\n",
              " 'tensorgraph',\n",
              " 'text_cnn',\n",
              " 'unicode_literals',\n",
              " 'xgboost_models']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cl4Ai8CSFYE"
      },
      "source": [
        "## 2. Parsing KIBA dataset\n",
        "\n",
        "Now we are ready to examine the Kinase dataset.  The way this works is that we are given a particular protein, and for that protein, we want to predict the small molecules that bind to it. Different proteins of course have different sets of small molecules.  This dataset contains a large set of proteins, and for each of them, it contains the small molecules that bind.\n",
        "\n",
        "To associate proteins with small molecules, we also need a representation of the proteins. Proteins are of course sequences of amino acids, so the representation is just a string of amino acids.   To use the string of amino acids with numbers. We do this by simply mapping each amino acid (represented by a letter) to a number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTIiSHZRSFYF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu_V0gH7SFYK"
      },
      "source": [
        "# for converting protein sequence to categorical format/numerical format\n",
        "seq_voc = \"ABCDEFGHIKLMNOPQRSTUVWXYZ\"\n",
        "seq_dict = {v:i for i,v in enumerate(seq_voc)}\n",
        "seq_dict_len = len(seq_dict)\n",
        "max_seq_len = 1000   # Note that all protein data will have the same length 1000 \n",
        "\n",
        "def seq_to_cat(prot):  # prot: protein\n",
        "    x = np.zeros(max_seq_len)\n",
        "    for i, ch in enumerate(prot[:max_seq_len]): \n",
        "        x[i] = seq_dict[ch]\n",
        "    return x  \n",
        "\n",
        "# for Concordance index evaluation\n",
        "def ci(y,f):\n",
        "    ind = np.argsort(y)  # np.argsort Returns the indices that would sort an array.\n",
        "    y = y[ind]\n",
        "    f = f[ind]\n",
        "    i = len(y)-1\n",
        "    j = i-1\n",
        "    z = 0.0\n",
        "    S = 0.0\n",
        "    while i > 0:\n",
        "        while j >= 0:\n",
        "            if y[i] > y[j]:\n",
        "                z = z+1\n",
        "                u = f[i] - f[j]\n",
        "                if u > 0:\n",
        "                    S = S + 1\n",
        "                elif u == 0:\n",
        "                    S = S + 0.5\n",
        "            j = j - 1\n",
        "        i = i - 1\n",
        "        j = i - 1\n",
        "    ci = S/z\n",
        "    return ci if z != 0 else 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_FG7L-Rn1oV"
      },
      "source": [
        "We read in the ligands and the proteins, as well as the binding data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5advqtV7SFYP",
        "scrolled": true
      },
      "source": [
        "fpath = G_PATH + '/data_Drug_target_binding_affinity/data/kiba/'\n",
        "# fpath = LOCAL_PATH + '/data_Drug_target_binding_affinity/data/kiba/'\n",
        "\n",
        "# Read in drugs and proteins\n",
        "drugs_ = json.load(open(fpath + \"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
        "drugs = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(d),isomericSmiles=True) for d in drugs_.values()])\n",
        "proteins_ = json.load(open(fpath + \"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
        "proteins = np.array(list(proteins_.values()))\n",
        "\n",
        "# Read in affinity data\n",
        "affinity = np.array(pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1'))\n",
        "\n",
        "# Read in train/test fold  \n",
        "train_fold = json.load(open(fpath + \"folds/train_fold_setting1.txt\"))\n",
        "train_fold = [ee for e in train_fold for ee in e ]    \n",
        "'''\n",
        "Here all validation folds are aggregated into training set. \n",
        "If you want to train models with different architectures and/or \n",
        "optimize for model hyperparameters, we encourage you to use 5-fold \n",
        "cross validation as provided here.\n",
        "'''\n",
        "test_fold = json.load(open(fpath + \"folds/test_fold_setting1.txt\"))\n",
        "\n",
        "# Prepare train/test data with fold indices\n",
        "rows, cols = np.where(np.isnan(affinity)==False) \n",
        "drugs_tr = drugs[rows[train_fold]]    # (98545,)\n",
        "proteins_tr = np.array([seq_to_cat(p) for p in proteins[cols[train_fold]]])   # (98545, 1000)\n",
        "affinity_tr = affinity[rows[train_fold], cols[train_fold]]  # (98545,)\n",
        "\n",
        "drugs_ts = drugs[rows[test_fold]] # (19709,)\n",
        "proteins_ts = np.array([seq_to_cat(p) for p in proteins[cols[test_fold]]]) # (19709, 1000)\n",
        "affinity_ts = affinity[rows[test_fold], cols[test_fold]]    # (19709,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GudunykUcni_",
        "outputId": "69b6118f-6488-4e3a-a11e-450d4aea057a"
      },
      "source": [
        "print('Example of drug:{}'.format(drugs_tr[0]))\n",
        "print('Example of protein:{} ...'.format(proteins_tr[0][:10]))\n",
        "print('Example of affinity score:{}'.format(affinity_tr[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of drug:O=C1c2c(c3c4ccc(O)cc4n(C4OC(CO)C(O)C(O)C4O)c3c3[nH]c4cc(O)ccc4c23)C(=O)N1NC(CO)CO\n",
            "Example of protein:[11. 17.  0. 12. 12. 17. 14. 14. 17.  0.] ...\n",
            "Example of affinity score:9.798970004000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9_fbrsHPXh4",
        "outputId": "56aa0a03-4d56-46aa-cbb3-22112ad7a8e1"
      },
      "source": [
        "# Convert to ECFP fingerprint\n",
        "smileToMol = lambda x: MolFromSmiles(x)  # molecules from smiles\n",
        "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
        "\n",
        "drugs_mol_tr = list(map(smileToMol, drugs_tr))\n",
        "drugs_ecfp_tr = featurizer.featurize(drugs_mol_tr)\n",
        "drugs_mol_ts = list(map(smileToMol, drugs_ts))\n",
        "drugs_ecfp_ts = featurizer.featurize(drugs_mol_ts)\n",
        "\n",
        "print(drugs_ecfp_tr.shape)\n",
        "print(drugs_ecfp_ts.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98545, 1024)\n",
            "(19709, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQbj9m7WldB6"
      },
      "source": [
        "tr_size, drug_size = drugs_ecfp_tr.shape[0], drugs_ecfp_tr.shape[1]\n",
        "ts_size = drugs_ecfp_ts.shape[0]\n",
        "\n",
        "protein_size = max_seq_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRXYpyYVSFYS"
      },
      "source": [
        "## 3. Train a model on KIBA data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19Q7cnDXScZV"
      },
      "source": [
        "### 3.1 Baseline Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ07j5QYydTn"
      },
      "source": [
        "#### (1) Model description:\n",
        "Here we first try a naive baseline prediction model that comprises two blocks, each of which aims to learn representations from SMILES strings and protein sequences. For each we used a FC layer to learn the representation of input data, since Fully-Connected Neural Networks are popular models for baseline. The final features layers were concatenated and fed into three FC layers, which is the DeepDTA, adopted from the paper “DeepDTA: deep drug–target binding affinity prediction”. Specifically, we used 1024 nodes in the first two FC layers, each followed by a dropout layer of rate 0.1 to avoid over-fitting. And the third layer consisted of 512 nodes and was followed by the output layer. Below is the summary of the model architecture. We also used Adam as the optimizer and MSE as the loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qODLvdvESFYT"
      },
      "source": [
        "# Have fun!\n",
        "import tensorflow as tf\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Dense, concatenate, Dropout\n",
        "\n",
        "def build_baseline_model(drug_size, protein_size):\n",
        "\n",
        "  drug_model = Sequential()\n",
        "  drug_model.add(Dense(1, input_shape=(drug_size,), activation='linear'))\n",
        "\n",
        "  protein_model = Sequential()\n",
        "  protein_model.add(Dense(1, input_shape=(protein_size,), activation='linear'))\n",
        "\n",
        "  # concat_layer = tf.keras.layers.Concatenate([drug_model.outputs[0], protein_model.outputs[0]])\n",
        "  model_concat = concatenate([drug_model.output, protein_model.output])\n",
        "  # fully connected\n",
        "  model_concat = Dense(1024, activation='relu')(model_concat)\n",
        "  model_concat = Dropout(0.1)(model_concat)\n",
        "  model_concat = Dense(1024, activation='relu')(model_concat)\n",
        "  model_concat = Dropout(0.1)(model_concat)\n",
        "  model_concat = Dense(512, activation='relu')(model_concat)\n",
        "  model_concat = Dense(1, kernel_initializer='normal')(model_concat)\n",
        "  \n",
        "  model = Model(inputs=[drug_model.input, protein_model.input], outputs=model_concat)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "model = build_baseline_model(drug_size=drug_size, protein_size=protein_size)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ViStDljpY7iN",
        "outputId": "d844d010-adb0-4050-f049-e5e1edaaba89"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 50\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "train_history = model.fit([drugs_ecfp_tr, proteins_tr], affinity_tr, \n",
        "                    validation_split=0.2, batch_size=batch_size, epochs=epochs, verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 78836 samples, validate on 19709 samples\n",
            "Epoch 1/100\n",
            "78836/78836 [==============================] - 68s 865us/step - loss: 0.5321 - mean_squared_error: 0.5321 - val_loss: 2.0868 - val_mean_squared_error: 2.0868\n",
            "Epoch 2/100\n",
            "78836/78836 [==============================] - 69s 873us/step - loss: 0.5283 - mean_squared_error: 0.5283 - val_loss: 2.1565 - val_mean_squared_error: 2.1565\n",
            "Epoch 3/100\n",
            "78836/78836 [==============================] - 67s 853us/step - loss: 0.5310 - mean_squared_error: 0.5310 - val_loss: 1.2997 - val_mean_squared_error: 1.2997\n",
            "Epoch 4/100\n",
            "78836/78836 [==============================] - 66s 838us/step - loss: 0.5190 - mean_squared_error: 0.5190 - val_loss: 1.6997 - val_mean_squared_error: 1.6997\n",
            "Epoch 5/100\n",
            "78836/78836 [==============================] - 67s 844us/step - loss: 0.5052 - mean_squared_error: 0.5052 - val_loss: 1.7902 - val_mean_squared_error: 1.7902\n",
            "Epoch 6/100\n",
            "78836/78836 [==============================] - 67s 855us/step - loss: 0.5030 - mean_squared_error: 0.5030 - val_loss: 0.9893 - val_mean_squared_error: 0.9893\n",
            "Epoch 7/100\n",
            "78836/78836 [==============================] - 68s 862us/step - loss: 0.4863 - mean_squared_error: 0.4863 - val_loss: 1.1108 - val_mean_squared_error: 1.1108\n",
            "Epoch 8/100\n",
            "78836/78836 [==============================] - 68s 864us/step - loss: 0.4741 - mean_squared_error: 0.4741 - val_loss: 1.1121 - val_mean_squared_error: 1.1121\n",
            "Epoch 9/100\n",
            "78836/78836 [==============================] - 69s 875us/step - loss: 0.4679 - mean_squared_error: 0.4679 - val_loss: 1.2602 - val_mean_squared_error: 1.2602\n",
            "Epoch 10/100\n",
            "78836/78836 [==============================] - 75s 950us/step - loss: 0.4689 - mean_squared_error: 0.4689 - val_loss: 0.7032 - val_mean_squared_error: 0.7032\n",
            "Epoch 11/100\n",
            "78836/78836 [==============================] - 69s 874us/step - loss: 0.4634 - mean_squared_error: 0.4634 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
            "Epoch 12/100\n",
            "78836/78836 [==============================] - 68s 869us/step - loss: 0.4532 - mean_squared_error: 0.4532 - val_loss: 1.0899 - val_mean_squared_error: 1.0899\n",
            "Epoch 13/100\n",
            "78836/78836 [==============================] - 68s 865us/step - loss: 0.4539 - mean_squared_error: 0.4539 - val_loss: 0.7825 - val_mean_squared_error: 0.7825\n",
            "Epoch 14/100\n",
            "78836/78836 [==============================] - 70s 892us/step - loss: 0.4447 - mean_squared_error: 0.4447 - val_loss: 0.7623 - val_mean_squared_error: 0.7623\n",
            "Epoch 15/100\n",
            "78836/78836 [==============================] - 70s 888us/step - loss: 0.4423 - mean_squared_error: 0.4423 - val_loss: 0.6661 - val_mean_squared_error: 0.6661\n",
            "Epoch 16/100\n",
            "78836/78836 [==============================] - 71s 899us/step - loss: 0.4376 - mean_squared_error: 0.4376 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 17/100\n",
            "78836/78836 [==============================] - 69s 874us/step - loss: 0.4366 - mean_squared_error: 0.4366 - val_loss: 0.5680 - val_mean_squared_error: 0.5680\n",
            "Epoch 18/100\n",
            "78836/78836 [==============================] - 69s 872us/step - loss: 0.4361 - mean_squared_error: 0.4361 - val_loss: 0.5950 - val_mean_squared_error: 0.5950\n",
            "Epoch 19/100\n",
            "78836/78836 [==============================] - 69s 881us/step - loss: 0.4388 - mean_squared_error: 0.4388 - val_loss: 0.5177 - val_mean_squared_error: 0.5177\n",
            "Epoch 20/100\n",
            "78836/78836 [==============================] - 70s 882us/step - loss: 0.4268 - mean_squared_error: 0.4268 - val_loss: 0.4211 - val_mean_squared_error: 0.4211\n",
            "Epoch 21/100\n",
            "78836/78836 [==============================] - 69s 876us/step - loss: 0.4268 - mean_squared_error: 0.4268 - val_loss: 0.4037 - val_mean_squared_error: 0.4037\n",
            "Epoch 22/100\n",
            "78836/78836 [==============================] - 70s 885us/step - loss: 0.4245 - mean_squared_error: 0.4245 - val_loss: 0.4666 - val_mean_squared_error: 0.4666\n",
            "Epoch 23/100\n",
            "78836/78836 [==============================] - 70s 883us/step - loss: 0.4260 - mean_squared_error: 0.4260 - val_loss: 0.4347 - val_mean_squared_error: 0.4347\n",
            "Epoch 24/100\n",
            "78836/78836 [==============================] - 73s 928us/step - loss: 0.4209 - mean_squared_error: 0.4209 - val_loss: 0.4373 - val_mean_squared_error: 0.4373\n",
            "Epoch 25/100\n",
            "78836/78836 [==============================] - 73s 920us/step - loss: 0.4202 - mean_squared_error: 0.4202 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
            "Epoch 26/100\n",
            "78836/78836 [==============================] - 74s 944us/step - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.3985 - val_mean_squared_error: 0.3985\n",
            "Epoch 27/100\n",
            "78836/78836 [==============================] - 73s 930us/step - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.4133 - val_mean_squared_error: 0.4133\n",
            "Epoch 28/100\n",
            "78836/78836 [==============================] - 73s 930us/step - loss: 0.4172 - mean_squared_error: 0.4172 - val_loss: 0.4011 - val_mean_squared_error: 0.4011\n",
            "Epoch 29/100\n",
            "78836/78836 [==============================] - 71s 899us/step - loss: 0.4152 - mean_squared_error: 0.4152 - val_loss: 0.4084 - val_mean_squared_error: 0.4084\n",
            "Epoch 30/100\n",
            "78836/78836 [==============================] - 74s 935us/step - loss: 0.4126 - mean_squared_error: 0.4126 - val_loss: 0.3969 - val_mean_squared_error: 0.3969\n",
            "Epoch 31/100\n",
            "78836/78836 [==============================] - 73s 921us/step - loss: 0.4150 - mean_squared_error: 0.4150 - val_loss: 0.4252 - val_mean_squared_error: 0.4252\n",
            "Epoch 32/100\n",
            "78836/78836 [==============================] - 73s 930us/step - loss: 0.4128 - mean_squared_error: 0.4128 - val_loss: 0.3986 - val_mean_squared_error: 0.3986\n",
            "Epoch 33/100\n",
            "78836/78836 [==============================] - 75s 951us/step - loss: 0.4123 - mean_squared_error: 0.4123 - val_loss: 0.3902 - val_mean_squared_error: 0.3902\n",
            "Epoch 34/100\n",
            "78836/78836 [==============================] - 75s 947us/step - loss: 0.4118 - mean_squared_error: 0.4118 - val_loss: 0.4294 - val_mean_squared_error: 0.4294\n",
            "Epoch 35/100\n",
            "78836/78836 [==============================] - 74s 942us/step - loss: 0.4136 - mean_squared_error: 0.4136 - val_loss: 0.3912 - val_mean_squared_error: 0.3912\n",
            "Epoch 36/100\n",
            "78836/78836 [==============================] - 74s 939us/step - loss: 0.4073 - mean_squared_error: 0.4073 - val_loss: 0.3938 - val_mean_squared_error: 0.3938\n",
            "Epoch 37/100\n",
            "78836/78836 [==============================] - 73s 922us/step - loss: 0.4093 - mean_squared_error: 0.4093 - val_loss: 0.4070 - val_mean_squared_error: 0.4070\n",
            "Epoch 38/100\n",
            "78836/78836 [==============================] - 70s 888us/step - loss: 0.4071 - mean_squared_error: 0.4071 - val_loss: 0.3885 - val_mean_squared_error: 0.3885\n",
            "Epoch 39/100\n",
            "78836/78836 [==============================] - 70s 889us/step - loss: 0.4057 - mean_squared_error: 0.4057 - val_loss: 0.4346 - val_mean_squared_error: 0.4346\n",
            "Epoch 40/100\n",
            "78836/78836 [==============================] - 70s 888us/step - loss: 0.4079 - mean_squared_error: 0.4079 - val_loss: 0.3941 - val_mean_squared_error: 0.3941\n",
            "Epoch 41/100\n",
            "78836/78836 [==============================] - 69s 877us/step - loss: 0.4059 - mean_squared_error: 0.4059 - val_loss: 0.4386 - val_mean_squared_error: 0.4386\n",
            "Epoch 42/100\n",
            "78836/78836 [==============================] - 70s 884us/step - loss: 0.4014 - mean_squared_error: 0.4014 - val_loss: 0.4010 - val_mean_squared_error: 0.4010\n",
            "Epoch 43/100\n",
            "78836/78836 [==============================] - 71s 899us/step - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.3840 - val_mean_squared_error: 0.3840\n",
            "Epoch 44/100\n",
            "78836/78836 [==============================] - 71s 902us/step - loss: 0.4022 - mean_squared_error: 0.4022 - val_loss: 0.4147 - val_mean_squared_error: 0.4147\n",
            "Epoch 45/100\n",
            "78836/78836 [==============================] - 72s 908us/step - loss: 0.4026 - mean_squared_error: 0.4026 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
            "Epoch 46/100\n",
            "78836/78836 [==============================] - 72s 912us/step - loss: 0.4045 - mean_squared_error: 0.4045 - val_loss: 0.3893 - val_mean_squared_error: 0.3893\n",
            "Epoch 47/100\n",
            "78836/78836 [==============================] - 71s 904us/step - loss: 0.4027 - mean_squared_error: 0.4027 - val_loss: 0.3894 - val_mean_squared_error: 0.3894\n",
            "Epoch 48/100\n",
            "78836/78836 [==============================] - 70s 886us/step - loss: 0.3981 - mean_squared_error: 0.3981 - val_loss: 0.3937 - val_mean_squared_error: 0.3937\n",
            "Epoch 49/100\n",
            "78836/78836 [==============================] - 70s 884us/step - loss: 0.4020 - mean_squared_error: 0.4020 - val_loss: 0.3835 - val_mean_squared_error: 0.3835\n",
            "Epoch 50/100\n",
            "78836/78836 [==============================] - 69s 878us/step - loss: 0.4016 - mean_squared_error: 0.4016 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
            "Epoch 51/100\n",
            "78836/78836 [==============================] - 70s 884us/step - loss: 0.3981 - mean_squared_error: 0.3981 - val_loss: 0.4069 - val_mean_squared_error: 0.4069\n",
            "Epoch 52/100\n",
            "78836/78836 [==============================] - 76s 958us/step - loss: 0.4037 - mean_squared_error: 0.4037 - val_loss: 0.3813 - val_mean_squared_error: 0.3813\n",
            "Epoch 53/100\n",
            "78836/78836 [==============================] - 77s 972us/step - loss: 0.3974 - mean_squared_error: 0.3974 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
            "Epoch 54/100\n",
            "78836/78836 [==============================] - 76s 961us/step - loss: 0.3990 - mean_squared_error: 0.3990 - val_loss: 0.3858 - val_mean_squared_error: 0.3858\n",
            "Epoch 55/100\n",
            "16950/78836 [=====>........................] - ETA: 58s - loss: 0.4072 - mean_squared_error: 0.4072"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-7683fedba07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m history = model.fit([drugs_ecfp_tr, proteins_tr], affinity_tr, \n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.2, batch_size=batch_size, epochs=epochs, verbose=True)\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4HOQGJKIiBt",
        "outputId": "a861821b-20be-4360-c2f5-96a72205f9ee"
      },
      "source": [
        "\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate([drugs_ecfp_ts, proteins_ts], affinity_ts, batch_size=128)\n",
        "print(\"test MSE loss is:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "19709/19709 [==============================] - 2s 105us/step\n",
            "test MSE loss is: [0.398003730737514, 0.3980037271976471]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_CH3ziCNDux"
      },
      "source": [
        "predicted_affinity = model.predict([drugs_ecfp_ts, proteins_ts])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT2skwaRPpm8",
        "outputId": "31a83482-b780-487d-b89f-06d7581d00d5"
      },
      "source": [
        "ci_score = ci(affinity_ts, predicted_affinity)\n",
        "print('test CI score is:', ci_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test CI score is: 0.7536044611424282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31MkVXLVy9hn"
      },
      "source": [
        "#### (2) Result:\n",
        "Training the model for 10 epochs, we tested the trained model on the test dataset. The model achieves the MSE of 0.398 and CI score of 0.754, which is slightly lower than the model presented in the original paper. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qm0PfZScZW"
      },
      "source": [
        "### 3.2 Train a CNN model on KIBA Data\n",
        "Drugs and protein are represented by 1-D vectors, which represent their structures in the numerical way. Whether a drug-protein binding has a high affinity score depends on whether the drug and protein have matching structures, especially the geometrical structures. CNN is a good method to identify geometrical shapes, thus we can use it to extract the geometrical characterstics of drugs and proteins, and predict the affinity score. To match the dimensions of drug and proteins vectors, we use 1D CNN here.\n",
        "\n",
        "The idea of CNN model is also from the paper \"DeepDTA: deep drug–target binding affinity prediction\"(https://academic.oup.com/bioinformatics/article/34/17/i821/5093245). For the structure of the CNN model, since drugs and proteins are two different inputs, it doesn't make sense to concatenate them together and use the concatenation as an input. So we use two CNN models ```drug_cnn``` and ```prot_cnn``` to take drugs and proteins as inputs respectively, and concatenate the outputs of these 2 CNN models to a new embedding, which is the input to the third CNN model ```cnn_concat```, then get the final CNN model ```cnn```. We also used the dropout layer to avoid overfitting and the dense layer to get the final result.\n",
        "\n",
        "The implementation and evaluation of the CNN model is as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmgM6bi0ScZW"
      },
      "source": [
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpP7GxYLk9xe"
      },
      "source": [
        "#### (1) Prepare data for CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b3TjeRyScZX"
      },
      "source": [
        "\n",
        "num_train, num_drugs = drugs_ecfp_tr.shape\n",
        "num_prot = proteins_tr.shape[1]\n",
        "drugs_tr_reshape = drugs_ecfp_tr.reshape((num_train, num_drugs, 1))\n",
        "proteins_tr_reshape = proteins_tr.reshape((num_train, num_prot, 1))\n",
        "\n",
        "# Testing data\n",
        "drug_ts_reshape = drugs_ecfp_ts.reshape((drugs_ecfp_ts.shape[0], drugs_ecfp_ts.shape[1], 1))\n",
        "proteins_ts_reshape = proteins_ts.reshape((proteins_ts.shape[0], proteins_ts.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZPwe5Mo5V6d"
      },
      "source": [
        "#### (2) Build and Train a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Jskv-E29do",
        "outputId": "284b4632-287f-4ad0-bc5e-5454c561abcc"
      },
      "source": [
        "# CNN \n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "def sub_cnn(input_dim):\n",
        "    cnn = Sequential() # Create sequential model\n",
        "    cnn.add(Conv1D(16, 3, activation='relu', input_shape=(input_dim, 1)))\n",
        "    cnn.add(MaxPooling1D(3))\n",
        "    cnn.add(Flatten())\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(16, activation = 'linear'))\n",
        "    return cnn\n",
        "drug_cnn = sub_cnn(num_drugs)\n",
        "prot_cnn = sub_cnn(num_prot)\n",
        "cnn_concat = concatenate([drug_cnn.output, prot_cnn.output])\n",
        "\n",
        "'''\n",
        "cnn_drug = Sequential() # Create sequential model\n",
        "cnn_drug.add(Conv1D(16, 3, activation='relu', input_shape=(num_drugs, 1)))\n",
        "cnn.add(MaxPooling1D(3))\n",
        "\n",
        "cnn_prot = Sequential()\n",
        "cnn_prot.add(Conv1D(16, 3, activation='relu', input_shape=(num_prot, 1)))\n",
        "cnn.add(MaxPooling1D(3))\n",
        "# Concatenate\n",
        "cnn = concatenate([cnn_drug.output, cnn_prot.output])\n",
        "'''\n",
        "\n",
        "cnn_concat = Dense(1024, activation='relu')(cnn_concat)\n",
        "cnn_concat = Dropout(0.1)(cnn_concat)\n",
        "cnn_concat = Dense(16, activation='relu')(cnn_concat)\n",
        "\n",
        "cnn_concat = Dense(1, activation='linear')(cnn_concat)\n",
        "\n",
        "cnn = Model(inputs=[drug_cnn.input, prot_cnn.input], outputs=cnn_concat)\n",
        "# Show model summary\n",
        "cnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv1d_3_input (InputLayer)     (None, 1024, 1)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4_input (InputLayer)     (None, 1000, 1)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 1022, 16)     64          conv1d_3_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 998, 16)      64          conv1d_4_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 340, 16)      0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 332, 16)      0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 5440)         0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 5312)         0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 5440)         0           flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 5312)         0           flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           87056       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           85008       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32)           0           dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1024)         33792       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 16)           16400       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            17          dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 222,401\n",
            "Trainable params: 222,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN-z_li53ets",
        "outputId": "c2f8588e-2791-4854-bc13-16188ae533f1"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "train_history = cnn.fit([drugs_tr_reshape, proteins_tr_reshape], affinity_tr, \n",
        "                    validation_split=0.2, batch_size=batch_size, epochs=epochs, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 78836 samples, validate on 19709 samples\n",
            "Epoch 1/100\n",
            "78836/78836 [==============================] - 66s 834us/step - loss: 2.6518 - mean_squared_error: 2.6518 - val_loss: 0.4968 - val_mean_squared_error: 0.4968\n",
            "Epoch 2/100\n",
            "78836/78836 [==============================] - 65s 821us/step - loss: 0.6922 - mean_squared_error: 0.6922 - val_loss: 0.5036 - val_mean_squared_error: 0.5036\n",
            "Epoch 3/100\n",
            "78836/78836 [==============================] - 64s 818us/step - loss: 0.6023 - mean_squared_error: 0.6023 - val_loss: 0.4733 - val_mean_squared_error: 0.4733\n",
            "Epoch 4/100\n",
            "78836/78836 [==============================] - 64s 815us/step - loss: 0.5789 - mean_squared_error: 0.5789 - val_loss: 0.4322 - val_mean_squared_error: 0.4322\n",
            "Epoch 5/100\n",
            "78836/78836 [==============================] - 64s 812us/step - loss: 0.5364 - mean_squared_error: 0.5364 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n",
            "Epoch 6/100\n",
            "78836/78836 [==============================] - 64s 813us/step - loss: 0.5053 - mean_squared_error: 0.5053 - val_loss: 0.3811 - val_mean_squared_error: 0.3811\n",
            "Epoch 7/100\n",
            "78836/78836 [==============================] - 64s 817us/step - loss: 0.4996 - mean_squared_error: 0.4996 - val_loss: 0.3812 - val_mean_squared_error: 0.3812\n",
            "Epoch 8/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.4779 - mean_squared_error: 0.4779 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
            "Epoch 9/100\n",
            "78836/78836 [==============================] - 68s 864us/step - loss: 0.4648 - mean_squared_error: 0.4648 - val_loss: 0.3677 - val_mean_squared_error: 0.3677\n",
            "Epoch 10/100\n",
            "78836/78836 [==============================] - 64s 815us/step - loss: 0.4560 - mean_squared_error: 0.4560 - val_loss: 0.3893 - val_mean_squared_error: 0.3893\n",
            "Epoch 11/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.4536 - mean_squared_error: 0.4536 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n",
            "Epoch 12/100\n",
            "78836/78836 [==============================] - 64s 815us/step - loss: 0.4430 - mean_squared_error: 0.4430 - val_loss: 0.3969 - val_mean_squared_error: 0.3969\n",
            "Epoch 13/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.4449 - mean_squared_error: 0.4449 - val_loss: 0.3353 - val_mean_squared_error: 0.3353\n",
            "Epoch 14/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.4205 - mean_squared_error: 0.4205 - val_loss: 0.3316 - val_mean_squared_error: 0.3316\n",
            "Epoch 15/100\n",
            "78836/78836 [==============================] - 64s 812us/step - loss: 0.4277 - mean_squared_error: 0.4277 - val_loss: 0.3246 - val_mean_squared_error: 0.3246\n",
            "Epoch 16/100\n",
            "78836/78836 [==============================] - 64s 812us/step - loss: 0.4023 - mean_squared_error: 0.4023 - val_loss: 0.3186 - val_mean_squared_error: 0.3186\n",
            "Epoch 17/100\n",
            "78836/78836 [==============================] - 64s 813us/step - loss: 0.4059 - mean_squared_error: 0.4059 - val_loss: 0.3189 - val_mean_squared_error: 0.3189\n",
            "Epoch 18/100\n",
            "78836/78836 [==============================] - 64s 812us/step - loss: 0.4004 - mean_squared_error: 0.4004 - val_loss: 0.3687 - val_mean_squared_error: 0.3687\n",
            "Epoch 19/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.3890 - mean_squared_error: 0.3890 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
            "Epoch 20/100\n",
            "78836/78836 [==============================] - 64s 815us/step - loss: 0.3895 - mean_squared_error: 0.3895 - val_loss: 0.3950 - val_mean_squared_error: 0.3950\n",
            "Epoch 21/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.3844 - mean_squared_error: 0.3844 - val_loss: 0.3665 - val_mean_squared_error: 0.3665\n",
            "Epoch 22/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
            "Epoch 23/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.3677 - mean_squared_error: 0.3677 - val_loss: 0.2937 - val_mean_squared_error: 0.2937\n",
            "Epoch 24/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.3705 - mean_squared_error: 0.3705 - val_loss: 0.3301 - val_mean_squared_error: 0.3301\n",
            "Epoch 25/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.3615 - mean_squared_error: 0.3615 - val_loss: 0.2836 - val_mean_squared_error: 0.2836\n",
            "Epoch 26/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.3556 - mean_squared_error: 0.3556 - val_loss: 0.2893 - val_mean_squared_error: 0.2893\n",
            "Epoch 27/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.3444 - mean_squared_error: 0.3444 - val_loss: 0.2947 - val_mean_squared_error: 0.2947\n",
            "Epoch 28/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.3471 - mean_squared_error: 0.3471 - val_loss: 0.2866 - val_mean_squared_error: 0.2866\n",
            "Epoch 29/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.2737 - val_mean_squared_error: 0.2737\n",
            "Epoch 30/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.3356 - mean_squared_error: 0.3356 - val_loss: 0.2685 - val_mean_squared_error: 0.2685\n",
            "Epoch 31/100\n",
            "78836/78836 [==============================] - 64s 809us/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.2662 - val_mean_squared_error: 0.2662\n",
            "Epoch 32/100\n",
            "78836/78836 [==============================] - 64s 809us/step - loss: 0.3297 - mean_squared_error: 0.3297 - val_loss: 0.2633 - val_mean_squared_error: 0.2633\n",
            "Epoch 33/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.3129 - mean_squared_error: 0.3129 - val_loss: 0.2583 - val_mean_squared_error: 0.2583\n",
            "Epoch 34/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.3181 - mean_squared_error: 0.3181 - val_loss: 0.2613 - val_mean_squared_error: 0.2613\n",
            "Epoch 35/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.3105 - mean_squared_error: 0.3105 - val_loss: 0.2586 - val_mean_squared_error: 0.2586\n",
            "Epoch 36/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.3097 - mean_squared_error: 0.3097 - val_loss: 0.2582 - val_mean_squared_error: 0.2582\n",
            "Epoch 37/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.3014 - mean_squared_error: 0.3014 - val_loss: 0.2677 - val_mean_squared_error: 0.2677\n",
            "Epoch 38/100\n",
            "78836/78836 [==============================] - 64s 807us/step - loss: 0.3007 - mean_squared_error: 0.3007 - val_loss: 0.2474 - val_mean_squared_error: 0.2474\n",
            "Epoch 39/100\n",
            "78836/78836 [==============================] - 66s 842us/step - loss: 0.2942 - mean_squared_error: 0.2942 - val_loss: 0.3089 - val_mean_squared_error: 0.3089\n",
            "Epoch 40/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2971 - mean_squared_error: 0.2971 - val_loss: 0.2620 - val_mean_squared_error: 0.2620\n",
            "Epoch 41/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2925 - mean_squared_error: 0.2925 - val_loss: 0.2780 - val_mean_squared_error: 0.2780\n",
            "Epoch 42/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2952 - mean_squared_error: 0.2952 - val_loss: 0.2433 - val_mean_squared_error: 0.2433\n",
            "Epoch 43/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2800 - mean_squared_error: 0.2800 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
            "Epoch 44/100\n",
            "78836/78836 [==============================] - 63s 802us/step - loss: 0.2806 - mean_squared_error: 0.2806 - val_loss: 0.2396 - val_mean_squared_error: 0.2396\n",
            "Epoch 45/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.2812 - mean_squared_error: 0.2812 - val_loss: 0.2531 - val_mean_squared_error: 0.2531\n",
            "Epoch 46/100\n",
            "78836/78836 [==============================] - 64s 807us/step - loss: 0.2730 - mean_squared_error: 0.2730 - val_loss: 0.2441 - val_mean_squared_error: 0.2441\n",
            "Epoch 47/100\n",
            "78836/78836 [==============================] - 64s 807us/step - loss: 0.2733 - mean_squared_error: 0.2733 - val_loss: 0.2705 - val_mean_squared_error: 0.2705\n",
            "Epoch 48/100\n",
            "78836/78836 [==============================] - 63s 805us/step - loss: 0.2756 - mean_squared_error: 0.2756 - val_loss: 0.2758 - val_mean_squared_error: 0.2758\n",
            "Epoch 49/100\n",
            "78836/78836 [==============================] - 64s 807us/step - loss: 0.2625 - mean_squared_error: 0.2625 - val_loss: 0.2556 - val_mean_squared_error: 0.2556\n",
            "Epoch 50/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2659 - mean_squared_error: 0.2659 - val_loss: 0.2278 - val_mean_squared_error: 0.2278\n",
            "Epoch 51/100\n",
            "78836/78836 [==============================] - 63s 805us/step - loss: 0.2592 - mean_squared_error: 0.2592 - val_loss: 0.2276 - val_mean_squared_error: 0.2276\n",
            "Epoch 52/100\n",
            "78836/78836 [==============================] - 64s 807us/step - loss: 0.2593 - mean_squared_error: 0.2593 - val_loss: 0.2390 - val_mean_squared_error: 0.2390\n",
            "Epoch 53/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2627 - mean_squared_error: 0.2627 - val_loss: 0.2527 - val_mean_squared_error: 0.2527\n",
            "Epoch 54/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2552 - mean_squared_error: 0.2552 - val_loss: 0.2337 - val_mean_squared_error: 0.2337\n",
            "Epoch 55/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.2549 - mean_squared_error: 0.2549 - val_loss: 0.2283 - val_mean_squared_error: 0.2283\n",
            "Epoch 56/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.2477 - mean_squared_error: 0.2477 - val_loss: 0.2213 - val_mean_squared_error: 0.2213\n",
            "Epoch 57/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2438 - mean_squared_error: 0.2438 - val_loss: 0.2189 - val_mean_squared_error: 0.2189\n",
            "Epoch 58/100\n",
            "78836/78836 [==============================] - 64s 809us/step - loss: 0.2504 - mean_squared_error: 0.2504 - val_loss: 0.2186 - val_mean_squared_error: 0.2186\n",
            "Epoch 59/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2418 - mean_squared_error: 0.2418 - val_loss: 0.2298 - val_mean_squared_error: 0.2298\n",
            "Epoch 60/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2392 - mean_squared_error: 0.2392 - val_loss: 0.2208 - val_mean_squared_error: 0.2208\n",
            "Epoch 61/100\n",
            "78836/78836 [==============================] - 63s 803us/step - loss: 0.2413 - mean_squared_error: 0.2413 - val_loss: 0.2130 - val_mean_squared_error: 0.2130\n",
            "Epoch 62/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2363 - mean_squared_error: 0.2363 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
            "Epoch 63/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2334 - mean_squared_error: 0.2334 - val_loss: 0.2107 - val_mean_squared_error: 0.2107\n",
            "Epoch 64/100\n",
            "78836/78836 [==============================] - 64s 809us/step - loss: 0.2338 - mean_squared_error: 0.2338 - val_loss: 0.2488 - val_mean_squared_error: 0.2488\n",
            "Epoch 65/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2320 - mean_squared_error: 0.2320 - val_loss: 0.2128 - val_mean_squared_error: 0.2128\n",
            "Epoch 66/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.2246 - mean_squared_error: 0.2246 - val_loss: 0.2085 - val_mean_squared_error: 0.2085\n",
            "Epoch 67/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.2305 - mean_squared_error: 0.2305 - val_loss: 0.2288 - val_mean_squared_error: 0.2288\n",
            "Epoch 68/100\n",
            "78836/78836 [==============================] - 64s 808us/step - loss: 0.2229 - mean_squared_error: 0.2229 - val_loss: 0.2122 - val_mean_squared_error: 0.2122\n",
            "Epoch 69/100\n",
            "78836/78836 [==============================] - 64s 811us/step - loss: 0.2221 - mean_squared_error: 0.2221 - val_loss: 0.2107 - val_mean_squared_error: 0.2107\n",
            "Epoch 70/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.2204 - mean_squared_error: 0.2204 - val_loss: 0.2091 - val_mean_squared_error: 0.2091\n",
            "Epoch 71/100\n",
            "78836/78836 [==============================] - 64s 814us/step - loss: 0.2148 - mean_squared_error: 0.2148 - val_loss: 0.2056 - val_mean_squared_error: 0.2056\n",
            "Epoch 72/100\n",
            "78836/78836 [==============================] - 64s 809us/step - loss: 0.2189 - mean_squared_error: 0.2189 - val_loss: 0.2145 - val_mean_squared_error: 0.2145\n",
            "Epoch 73/100\n",
            "78836/78836 [==============================] - 63s 802us/step - loss: 0.2154 - mean_squared_error: 0.2154 - val_loss: 0.2288 - val_mean_squared_error: 0.2288\n",
            "Epoch 74/100\n",
            "78836/78836 [==============================] - 63s 800us/step - loss: 0.2122 - mean_squared_error: 0.2122 - val_loss: 0.2044 - val_mean_squared_error: 0.2044\n",
            "Epoch 75/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2113 - mean_squared_error: 0.2113 - val_loss: 0.2089 - val_mean_squared_error: 0.2089\n",
            "Epoch 76/100\n",
            "78836/78836 [==============================] - 63s 802us/step - loss: 0.2088 - mean_squared_error: 0.2088 - val_loss: 0.2318 - val_mean_squared_error: 0.2318\n",
            "Epoch 77/100\n",
            "78836/78836 [==============================] - 63s 803us/step - loss: 0.2077 - mean_squared_error: 0.2077 - val_loss: 0.2277 - val_mean_squared_error: 0.2277\n",
            "Epoch 78/100\n",
            "78836/78836 [==============================] - 63s 802us/step - loss: 0.2058 - mean_squared_error: 0.2058 - val_loss: 0.2017 - val_mean_squared_error: 0.2017\n",
            "Epoch 79/100\n",
            "78836/78836 [==============================] - 64s 810us/step - loss: 0.2088 - mean_squared_error: 0.2088 - val_loss: 0.2000 - val_mean_squared_error: 0.2000\n",
            "Epoch 80/100\n",
            "78836/78836 [==============================] - 63s 804us/step - loss: 0.2044 - mean_squared_error: 0.2044 - val_loss: 0.1966 - val_mean_squared_error: 0.1966\n",
            "Epoch 81/100\n",
            "78836/78836 [==============================] - 64s 806us/step - loss: 0.2014 - mean_squared_error: 0.2014 - val_loss: 0.1984 - val_mean_squared_error: 0.1984\n",
            "Epoch 82/100\n",
            "78836/78836 [==============================] - 63s 800us/step - loss: 0.1997 - mean_squared_error: 0.1997 - val_loss: 0.1957 - val_mean_squared_error: 0.1957\n",
            "Epoch 83/100\n",
            "78836/78836 [==============================] - 63s 800us/step - loss: 0.2003 - mean_squared_error: 0.2003 - val_loss: 0.2129 - val_mean_squared_error: 0.2129\n",
            "Epoch 84/100\n",
            "78836/78836 [==============================] - 63s 801us/step - loss: 0.2000 - mean_squared_error: 0.2000 - val_loss: 0.2079 - val_mean_squared_error: 0.2079\n",
            "Epoch 85/100\n",
            "78836/78836 [==============================] - 63s 800us/step - loss: 0.1980 - mean_squared_error: 0.1980 - val_loss: 0.2019 - val_mean_squared_error: 0.2019\n",
            "Epoch 86/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1960 - mean_squared_error: 0.1960 - val_loss: 0.1962 - val_mean_squared_error: 0.1962\n",
            "Epoch 87/100\n",
            "78836/78836 [==============================] - 63s 798us/step - loss: 0.1953 - mean_squared_error: 0.1953 - val_loss: 0.1979 - val_mean_squared_error: 0.1979\n",
            "Epoch 88/100\n",
            "78836/78836 [==============================] - 63s 798us/step - loss: 0.1904 - mean_squared_error: 0.1904 - val_loss: 0.1928 - val_mean_squared_error: 0.1928\n",
            "Epoch 89/100\n",
            "78836/78836 [==============================] - 63s 798us/step - loss: 0.1885 - mean_squared_error: 0.1885 - val_loss: 0.2047 - val_mean_squared_error: 0.2047\n",
            "Epoch 90/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1883 - mean_squared_error: 0.1883 - val_loss: 0.1985 - val_mean_squared_error: 0.1985\n",
            "Epoch 91/100\n",
            "78836/78836 [==============================] - 63s 796us/step - loss: 0.1884 - mean_squared_error: 0.1884 - val_loss: 0.1996 - val_mean_squared_error: 0.1996\n",
            "Epoch 92/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1861 - mean_squared_error: 0.1861 - val_loss: 0.1943 - val_mean_squared_error: 0.1943\n",
            "Epoch 93/100\n",
            "78836/78836 [==============================] - 63s 798us/step - loss: 0.1822 - mean_squared_error: 0.1822 - val_loss: 0.1920 - val_mean_squared_error: 0.1920\n",
            "Epoch 94/100\n",
            "78836/78836 [==============================] - 63s 803us/step - loss: 0.1849 - mean_squared_error: 0.1849 - val_loss: 0.2007 - val_mean_squared_error: 0.2007\n",
            "Epoch 95/100\n",
            "78836/78836 [==============================] - 63s 798us/step - loss: 0.1801 - mean_squared_error: 0.1801 - val_loss: 0.1902 - val_mean_squared_error: 0.1902\n",
            "Epoch 96/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1791 - mean_squared_error: 0.1791 - val_loss: 0.1965 - val_mean_squared_error: 0.1965\n",
            "Epoch 97/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1820 - mean_squared_error: 0.1820 - val_loss: 0.2038 - val_mean_squared_error: 0.2038\n",
            "Epoch 98/100\n",
            "78836/78836 [==============================] - 63s 803us/step - loss: 0.1778 - mean_squared_error: 0.1778 - val_loss: 0.1922 - val_mean_squared_error: 0.1922\n",
            "Epoch 99/100\n",
            "78836/78836 [==============================] - 63s 800us/step - loss: 0.1779 - mean_squared_error: 0.1779 - val_loss: 0.1955 - val_mean_squared_error: 0.1955\n",
            "Epoch 100/100\n",
            "78836/78836 [==============================] - 63s 799us/step - loss: 0.1785 - mean_squared_error: 0.1785 - val_loss: 0.1995 - val_mean_squared_error: 0.1995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ5F_04HlGlr"
      },
      "source": [
        "#### (3) Evaluate the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWILfOf0ScZY",
        "outputId": "4e25b80e-e40a-484e-a23e-e170ba490cdb"
      },
      "source": [
        "drug_ts_reshape = drugs_ecfp_ts.reshape((drugs_ecfp_ts.shape[0], drugs_ecfp_ts.shape[1], 1))\n",
        "proteins_ts_reshape = proteins_ts.reshape((proteins_ts.shape[0], proteins_ts.shape[1], 1))\n",
        "print(\"Evaluate on test data\")\n",
        "results = cnn.evaluate([drug_ts_reshape, proteins_ts_reshape], affinity_ts, batch_size=128)\n",
        "print(\"test MSE loss is:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "19709/19709 [==============================] - 6s 301us/step\n",
            "test MSE loss is: [0.21053694547722707, 0.21053697168827057]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVrzgBQSlU-9",
        "outputId": "209be4ac-567c-4c9c-f9d3-5241920f9a9a"
      },
      "source": [
        "predicted_affinity = cnn.predict([drug_ts_reshape, proteins_ts_reshape])\n",
        "ci_score = ci(affinity_ts, predicted_affinity)\n",
        "print('test CI score is:', ci_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test CI score is: 0.8394054274277895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K67QchKnSFYZ"
      },
      "source": [
        "[The original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4364066/) obtained CI score of 0.782 and MSE of 0.411, and [random forest model](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5395521/) got 0.836 and 0.222. Can you beat them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU81xXh2AnBX"
      },
      "source": [
        "The CNN models has MSE = 0.21053694547722707, and CI score = 0.8394054274277895 on the test set. \n",
        "Both the MSE value and the CI score of the CNN model beat the above baseline model, the original paper, and the random forest model. It's possibly because that CNN models can extract the underlying characteristics of drugs and proteins better than the Kronecker RLS method used in the original paper. \n",
        "\n",
        "The performance is just a little better than that of the random forest model, but we haven't use the cross validation which was used in the paper for model selection. Let's use cross validation and see if it would improve the performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hjKbW600Uuy"
      },
      "source": [
        "#### (4) Cross Validation on CNN\n",
        "\n",
        "Since a CNN model has so many parameters, it's hard to get the best value of each parameter by cross validation, but we can get the final prediction results by averaging the predicitons from each fold's model. Although some cross validation uses training data and testing data as a whole dataset for data splitting, here we do not touch testing data while training the models. We do 5-fold cross validation on the training data set, and do prediciton and model evaluation on the test data set. \n",
        "\n",
        "In the model training below, we do not set validation_split parameter, i.e. validation_split = 0. So the cross validaiton here is more like training data with 5 different validation sets, and the test indices from the ```kfold.split()``` function work as the validation indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnA5Dj5YtyaL",
        "outputId": "ddd3f162-f490-4e0d-9a8c-03f6efbc3057"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "epochs = 80\n",
        "batch_size = 256\n",
        "\n",
        "def sub_cnn(input_dim):\n",
        "    cnn = Sequential() # Create sequential model\n",
        "    cnn.add(Conv1D(16, 3, activation='relu', input_shape=(input_dim, 1)))\n",
        "    cnn.add(MaxPooling1D(3))\n",
        "    cnn.add(Flatten())\n",
        "    cnn.add(Dropout(0.1))\n",
        "    cnn.add(Dense(16, activation = 'linear'))\n",
        "    return cnn\n",
        "\n",
        "def cnn(i, x, y): \n",
        "  drug_cnn = sub_cnn(num_drugs)\n",
        "  prot_cnn = sub_cnn(num_prot)\n",
        "  cnn_concat = concatenate([drug_cnn.output, prot_cnn.output])\n",
        "  cnn_concat = Dense(1024, activation='relu')(cnn_concat)\n",
        "  cnn_concat = Dropout(0.1)(cnn_concat)\n",
        "  cnn_concat = Dense(16, activation='relu')(cnn_concat)\n",
        "\n",
        "  cnn_concat = Dense(1, activation='linear')(cnn_concat)\n",
        "\n",
        "  cnn = Model(inputs=[drug_cnn.input, prot_cnn.input], outputs=cnn_concat)\n",
        "  # Show model summary\n",
        "  cnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "  callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "  train_history = cnn.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=True)\n",
        "  # save the trained model for later use\n",
        "  \n",
        "  save_folder = f'{G_PATH}/saved_models/'\n",
        "  os.makedirs(save_folder, exist_ok=True)\n",
        "  save_path = save_folder + 'cnn_model_fold_{}'.format(i)\n",
        "  cnn.save(save_path)\n",
        "  print('model_{} saved'.format(i))\n",
        "  return cnn\n",
        "\n",
        "i = 1\n",
        "models = []\n",
        "cv_mse = []\n",
        "MSE = []\n",
        "cis = []\n",
        "for train, test in kfold.split(drugs_tr_reshape, affinity_tr):\n",
        "  # Define the model architecture\n",
        "  x = [drugs_tr_reshape[train], proteins_tr_reshape[train]]\n",
        "  y = affinity_tr[train]\n",
        "  model = cnn(i, x, y)\n",
        "  \n",
        "  scores = model.evaluate([drugs_tr_reshape[test], proteins_tr_reshape[test]], affinity_tr[test], verbose=0)\n",
        "  cv_mse.append(scores[1])\n",
        "  print(\"Evaluate on test data by model {}\".format(i))\n",
        "  results = model.evaluate([drug_ts_reshape, proteins_ts_reshape], affinity_ts, batch_size=128)\n",
        "  MSE.append(results[1])\n",
        "  print(\"test MSE loss is:\", results)\n",
        "  predicted_affinity = model.predict([drug_ts_reshape, proteins_ts_reshape])\n",
        "  ci_score = ci(affinity_ts, predicted_affinity)\n",
        "  print('test CI score is:', ci_score)\n",
        "  cis.append(ci_score)\n",
        "  i += 1\n",
        "\n",
        "save_folder = f'{G_PATH}/saved_results/'\n",
        "with open(save_folder + \"cv_mse.txt\", \"wb\") as f:\n",
        "  pickle.dump(cv_mse, f)\n",
        "with open(save_folder + 'MSE.txt', 'wb') as f:\n",
        "  pickle.dump(MSE, f)\n",
        "with open(save_folder + 'CI.txt', 'wb') as f:\n",
        "  pickle.dump(cis, f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 2.4288 - mean_squared_error: 2.4288\n",
            "Epoch 2/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.6623 - mean_squared_error: 0.6623\n",
            "Epoch 3/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.5858 - mean_squared_error: 0.5858\n",
            "Epoch 4/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.5541 - mean_squared_error: 0.5541\n",
            "Epoch 5/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.5193 - mean_squared_error: 0.5193\n",
            "Epoch 6/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.4930 - mean_squared_error: 0.4930\n",
            "Epoch 7/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.4862 - mean_squared_error: 0.4862\n",
            "Epoch 8/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.4784 - mean_squared_error: 0.4784\n",
            "Epoch 9/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.4763 - mean_squared_error: 0.4763\n",
            "Epoch 10/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.4509 - mean_squared_error: 0.4509\n",
            "Epoch 11/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.4448 - mean_squared_error: 0.4448\n",
            "Epoch 12/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.4419 - mean_squared_error: 0.4419\n",
            "Epoch 13/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.4392 - mean_squared_error: 0.4392\n",
            "Epoch 14/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.4325 - mean_squared_error: 0.4325\n",
            "Epoch 15/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.4164 - mean_squared_error: 0.4164\n",
            "Epoch 16/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.4215 - mean_squared_error: 0.4215\n",
            "Epoch 17/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.4159 - mean_squared_error: 0.4159\n",
            "Epoch 18/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.4031 - mean_squared_error: 0.4031\n",
            "Epoch 19/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.3991 - mean_squared_error: 0.3991\n",
            "Epoch 20/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.3958 - mean_squared_error: 0.3958\n",
            "Epoch 21/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.3855 - mean_squared_error: 0.3855\n",
            "Epoch 22/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.3979 - mean_squared_error: 0.3979\n",
            "Epoch 23/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.3763 - mean_squared_error: 0.3763\n",
            "Epoch 24/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.3697 - mean_squared_error: 0.3697\n",
            "Epoch 25/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3766 - mean_squared_error: 0.3766\n",
            "Epoch 26/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3638 - mean_squared_error: 0.3638\n",
            "Epoch 27/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3635 - mean_squared_error: 0.3635\n",
            "Epoch 28/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.3547 - mean_squared_error: 0.3547\n",
            "Epoch 29/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3477 - mean_squared_error: 0.3477\n",
            "Epoch 30/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.3490 - mean_squared_error: 0.3490\n",
            "Epoch 31/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3394 - mean_squared_error: 0.3394\n",
            "Epoch 32/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3368 - mean_squared_error: 0.3368\n",
            "Epoch 33/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3318 - mean_squared_error: 0.3318\n",
            "Epoch 34/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3239 - mean_squared_error: 0.3239\n",
            "Epoch 35/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3263 - mean_squared_error: 0.3263\n",
            "Epoch 36/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3221 - mean_squared_error: 0.3221\n",
            "Epoch 37/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3211 - mean_squared_error: 0.3211\n",
            "Epoch 38/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.3185 - mean_squared_error: 0.3185\n",
            "Epoch 39/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3208 - mean_squared_error: 0.3208\n",
            "Epoch 40/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3059 - mean_squared_error: 0.3059\n",
            "Epoch 41/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.3044 - mean_squared_error: 0.3044\n",
            "Epoch 42/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3020 - mean_squared_error: 0.3020\n",
            "Epoch 43/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2955 - mean_squared_error: 0.2955\n",
            "Epoch 44/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2979 - mean_squared_error: 0.2979\n",
            "Epoch 45/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2939 - mean_squared_error: 0.2939\n",
            "Epoch 46/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2862 - mean_squared_error: 0.2862\n",
            "Epoch 47/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2898 - mean_squared_error: 0.2898\n",
            "Epoch 48/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2862 - mean_squared_error: 0.2862\n",
            "Epoch 49/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2843 - mean_squared_error: 0.2843\n",
            "Epoch 50/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2835 - mean_squared_error: 0.2835\n",
            "Epoch 51/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2767 - mean_squared_error: 0.2767\n",
            "Epoch 52/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2725 - mean_squared_error: 0.2725\n",
            "Epoch 53/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2719 - mean_squared_error: 0.2719\n",
            "Epoch 54/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2713 - mean_squared_error: 0.2713\n",
            "Epoch 55/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2690 - mean_squared_error: 0.2690\n",
            "Epoch 56/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2714 - mean_squared_error: 0.2714\n",
            "Epoch 57/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2633 - mean_squared_error: 0.2633\n",
            "Epoch 58/80\n",
            "78836/78836 [==============================] - 34s 438us/step - loss: 0.2686 - mean_squared_error: 0.2686\n",
            "Epoch 59/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2652 - mean_squared_error: 0.2652\n",
            "Epoch 60/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2559 - mean_squared_error: 0.2559\n",
            "Epoch 61/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2589 - mean_squared_error: 0.2589\n",
            "Epoch 62/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2586 - mean_squared_error: 0.2586\n",
            "Epoch 63/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2571 - mean_squared_error: 0.2571\n",
            "Epoch 64/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2520 - mean_squared_error: 0.2520\n",
            "Epoch 65/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2531 - mean_squared_error: 0.2531\n",
            "Epoch 66/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2483 - mean_squared_error: 0.2483\n",
            "Epoch 67/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2466 - mean_squared_error: 0.2466\n",
            "Epoch 68/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2516 - mean_squared_error: 0.2516\n",
            "Epoch 69/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2515 - mean_squared_error: 0.2515\n",
            "Epoch 70/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2402 - mean_squared_error: 0.2402\n",
            "Epoch 71/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2439 - mean_squared_error: 0.2439\n",
            "Epoch 72/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2431 - mean_squared_error: 0.2431\n",
            "Epoch 73/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2369 - mean_squared_error: 0.2369\n",
            "Epoch 74/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2404 - mean_squared_error: 0.2404\n",
            "Epoch 75/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2384 - mean_squared_error: 0.2384\n",
            "Epoch 76/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2351 - mean_squared_error: 0.2351\n",
            "Epoch 77/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2369 - mean_squared_error: 0.2369\n",
            "Epoch 78/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2314 - mean_squared_error: 0.2314\n",
            "Epoch 79/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2326 - mean_squared_error: 0.2326\n",
            "Epoch 80/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2263 - mean_squared_error: 0.2263\n",
            "model_1 saved\n",
            "Evaluate on test data by model 1\n",
            "19709/19709 [==============================] - 4s 203us/step\n",
            "test MSE loss is: [0.21669217522718076, 0.2166922241449356]\n",
            "test CI score is: 0.8308648754096735\n",
            "Epoch 1/80\n",
            "78836/78836 [==============================] - 40s 506us/step - loss: 2.4089 - mean_squared_error: 2.4089\n",
            "Epoch 2/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.6856 - mean_squared_error: 0.6856\n",
            "Epoch 3/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.6004 - mean_squared_error: 0.6004\n",
            "Epoch 4/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.5454 - mean_squared_error: 0.5454\n",
            "Epoch 5/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.5071 - mean_squared_error: 0.5071\n",
            "Epoch 6/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.4936 - mean_squared_error: 0.4936\n",
            "Epoch 7/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.4797 - mean_squared_error: 0.4797\n",
            "Epoch 8/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.4743 - mean_squared_error: 0.4743\n",
            "Epoch 9/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.4571 - mean_squared_error: 0.4571\n",
            "Epoch 10/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.4485 - mean_squared_error: 0.4485\n",
            "Epoch 11/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.4425 - mean_squared_error: 0.4425\n",
            "Epoch 12/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.4265 - mean_squared_error: 0.4265\n",
            "Epoch 13/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.4297 - mean_squared_error: 0.4297\n",
            "Epoch 14/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.4149 - mean_squared_error: 0.4149\n",
            "Epoch 15/80\n",
            "78836/78836 [==============================] - 34s 430us/step - loss: 0.4119 - mean_squared_error: 0.4119\n",
            "Epoch 16/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.4001 - mean_squared_error: 0.4001\n",
            "Epoch 17/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.4029 - mean_squared_error: 0.4029\n",
            "Epoch 18/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.3954 - mean_squared_error: 0.3954\n",
            "Epoch 19/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3913 - mean_squared_error: 0.3913\n",
            "Epoch 20/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.3745 - mean_squared_error: 0.3745\n",
            "Epoch 21/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.3746 - mean_squared_error: 0.3746\n",
            "Epoch 22/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.3713 - mean_squared_error: 0.3713\n",
            "Epoch 23/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.3684 - mean_squared_error: 0.3684\n",
            "Epoch 24/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3689 - mean_squared_error: 0.3689\n",
            "Epoch 25/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3532 - mean_squared_error: 0.3532\n",
            "Epoch 26/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3525 - mean_squared_error: 0.3525\n",
            "Epoch 27/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3498 - mean_squared_error: 0.3498\n",
            "Epoch 28/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3414 - mean_squared_error: 0.3414\n",
            "Epoch 29/80\n",
            "78836/78836 [==============================] - 34s 438us/step - loss: 0.3359 - mean_squared_error: 0.3359\n",
            "Epoch 30/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3271 - mean_squared_error: 0.3271\n",
            "Epoch 31/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3259 - mean_squared_error: 0.3259\n",
            "Epoch 32/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3251 - mean_squared_error: 0.3251\n",
            "Epoch 33/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3146 - mean_squared_error: 0.3146\n",
            "Epoch 34/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3174 - mean_squared_error: 0.3174\n",
            "Epoch 35/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3073 - mean_squared_error: 0.3073\n",
            "Epoch 36/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3094 - mean_squared_error: 0.3094\n",
            "Epoch 37/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.3001 - mean_squared_error: 0.3001\n",
            "Epoch 38/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2948 - mean_squared_error: 0.2948\n",
            "Epoch 39/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2961 - mean_squared_error: 0.2961\n",
            "Epoch 40/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2892 - mean_squared_error: 0.2892\n",
            "Epoch 41/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2870 - mean_squared_error: 0.2870\n",
            "Epoch 42/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2779 - mean_squared_error: 0.2779\n",
            "Epoch 43/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2766 - mean_squared_error: 0.2766\n",
            "Epoch 44/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2790 - mean_squared_error: 0.2790\n",
            "Epoch 45/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2669 - mean_squared_error: 0.2669\n",
            "Epoch 46/80\n",
            "78836/78836 [==============================] - 34s 430us/step - loss: 0.2651 - mean_squared_error: 0.2651\n",
            "Epoch 47/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2656 - mean_squared_error: 0.2656\n",
            "Epoch 48/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2669 - mean_squared_error: 0.2669\n",
            "Epoch 49/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2590 - mean_squared_error: 0.2590\n",
            "Epoch 50/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2554 - mean_squared_error: 0.2554\n",
            "Epoch 51/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2495 - mean_squared_error: 0.2495\n",
            "Epoch 52/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2463 - mean_squared_error: 0.2463\n",
            "Epoch 53/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2463 - mean_squared_error: 0.2463\n",
            "Epoch 54/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2442 - mean_squared_error: 0.2442\n",
            "Epoch 55/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2392 - mean_squared_error: 0.2392\n",
            "Epoch 56/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2438 - mean_squared_error: 0.2438\n",
            "Epoch 57/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2359 - mean_squared_error: 0.2359\n",
            "Epoch 58/80\n",
            "78836/78836 [==============================] - 34s 430us/step - loss: 0.2308 - mean_squared_error: 0.2308\n",
            "Epoch 59/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2304 - mean_squared_error: 0.2304\n",
            "Epoch 60/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2289 - mean_squared_error: 0.2289\n",
            "Epoch 61/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2239 - mean_squared_error: 0.2239\n",
            "Epoch 62/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2229 - mean_squared_error: 0.2229\n",
            "Epoch 63/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2227 - mean_squared_error: 0.2227\n",
            "Epoch 64/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2223 - mean_squared_error: 0.2223\n",
            "Epoch 65/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2158 - mean_squared_error: 0.2158\n",
            "Epoch 66/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2161 - mean_squared_error: 0.2161\n",
            "Epoch 67/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2144 - mean_squared_error: 0.2144\n",
            "Epoch 68/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2113 - mean_squared_error: 0.2113\n",
            "Epoch 69/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2123 - mean_squared_error: 0.2123\n",
            "Epoch 70/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2092 - mean_squared_error: 0.2092\n",
            "Epoch 71/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2112 - mean_squared_error: 0.2112\n",
            "Epoch 72/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2078 - mean_squared_error: 0.2078\n",
            "Epoch 73/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2059 - mean_squared_error: 0.2059\n",
            "Epoch 74/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2044 - mean_squared_error: 0.2044\n",
            "Epoch 75/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2012 - mean_squared_error: 0.2012\n",
            "Epoch 76/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2009 - mean_squared_error: 0.2009\n",
            "Epoch 77/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.1990 - mean_squared_error: 0.1990\n",
            "Epoch 78/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.1990 - mean_squared_error: 0.1990\n",
            "Epoch 79/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.1984 - mean_squared_error: 0.1984\n",
            "Epoch 80/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.1941 - mean_squared_error: 0.1941\n",
            "model_2 saved\n",
            "Evaluate on test data by model 2\n",
            "19709/19709 [==============================] - 4s 206us/step\n",
            "test MSE loss is: [0.2068727552214861, 0.20687276124954224]\n",
            "test CI score is: 0.837279303625419\n",
            "Epoch 1/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 2.7985 - mean_squared_error: 2.7985\n",
            "Epoch 2/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.6739 - mean_squared_error: 0.6739\n",
            "Epoch 3/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.6188 - mean_squared_error: 0.6188\n",
            "Epoch 4/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.5738 - mean_squared_error: 0.5738\n",
            "Epoch 5/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.5447 - mean_squared_error: 0.5447\n",
            "Epoch 6/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.5451 - mean_squared_error: 0.5451\n",
            "Epoch 7/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.5003 - mean_squared_error: 0.5003\n",
            "Epoch 8/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.5099 - mean_squared_error: 0.5099\n",
            "Epoch 9/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.4964 - mean_squared_error: 0.4964\n",
            "Epoch 10/80\n",
            "78836/78836 [==============================] - 36s 454us/step - loss: 0.4619 - mean_squared_error: 0.4619\n",
            "Epoch 11/80\n",
            "78836/78836 [==============================] - 35s 450us/step - loss: 0.4465 - mean_squared_error: 0.4465\n",
            "Epoch 12/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.4496 - mean_squared_error: 0.4496\n",
            "Epoch 13/80\n",
            "78836/78836 [==============================] - 35s 450us/step - loss: 0.4518 - mean_squared_error: 0.4518\n",
            "Epoch 14/80\n",
            "78836/78836 [==============================] - 38s 482us/step - loss: 0.4318 - mean_squared_error: 0.4318\n",
            "Epoch 15/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 0.4181 - mean_squared_error: 0.4181\n",
            "Epoch 16/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.4192 - mean_squared_error: 0.4192\n",
            "Epoch 17/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.4233 - mean_squared_error: 0.4233\n",
            "Epoch 18/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.4073 - mean_squared_error: 0.4073\n",
            "Epoch 19/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3989 - mean_squared_error: 0.3989\n",
            "Epoch 20/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3892 - mean_squared_error: 0.3892\n",
            "Epoch 21/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3888 - mean_squared_error: 0.3888\n",
            "Epoch 22/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3728 - mean_squared_error: 0.3728\n",
            "Epoch 23/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3694 - mean_squared_error: 0.3694\n",
            "Epoch 24/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3561 - mean_squared_error: 0.3561\n",
            "Epoch 25/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3546 - mean_squared_error: 0.3546\n",
            "Epoch 26/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3534 - mean_squared_error: 0.3534\n",
            "Epoch 27/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3437 - mean_squared_error: 0.3437\n",
            "Epoch 28/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.3397 - mean_squared_error: 0.3397\n",
            "Epoch 29/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3339 - mean_squared_error: 0.3339\n",
            "Epoch 30/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3323 - mean_squared_error: 0.3323\n",
            "Epoch 31/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3291 - mean_squared_error: 0.3291\n",
            "Epoch 32/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3231 - mean_squared_error: 0.3231\n",
            "Epoch 33/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3150 - mean_squared_error: 0.3150\n",
            "Epoch 34/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3201 - mean_squared_error: 0.3201\n",
            "Epoch 35/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3204 - mean_squared_error: 0.3204\n",
            "Epoch 36/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.3040 - mean_squared_error: 0.3040\n",
            "Epoch 37/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2996 - mean_squared_error: 0.2996\n",
            "Epoch 38/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2999 - mean_squared_error: 0.2999\n",
            "Epoch 39/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2989 - mean_squared_error: 0.2989\n",
            "Epoch 40/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2961 - mean_squared_error: 0.2961\n",
            "Epoch 41/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2955 - mean_squared_error: 0.2955\n",
            "Epoch 42/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2894 - mean_squared_error: 0.2894\n",
            "Epoch 43/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2802 - mean_squared_error: 0.2802\n",
            "Epoch 44/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2846 - mean_squared_error: 0.2846\n",
            "Epoch 45/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2782 - mean_squared_error: 0.2782\n",
            "Epoch 46/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2795 - mean_squared_error: 0.2795\n",
            "Epoch 47/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2780 - mean_squared_error: 0.2780\n",
            "Epoch 48/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2663 - mean_squared_error: 0.2663\n",
            "Epoch 49/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2770 - mean_squared_error: 0.2770\n",
            "Epoch 50/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2674 - mean_squared_error: 0.2674\n",
            "Epoch 51/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2692 - mean_squared_error: 0.2692\n",
            "Epoch 52/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2608 - mean_squared_error: 0.2608\n",
            "Epoch 53/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2587 - mean_squared_error: 0.2587\n",
            "Epoch 54/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2637 - mean_squared_error: 0.2637\n",
            "Epoch 55/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2515 - mean_squared_error: 0.2515\n",
            "Epoch 56/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2559 - mean_squared_error: 0.2559\n",
            "Epoch 57/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2490 - mean_squared_error: 0.2490\n",
            "Epoch 58/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2514 - mean_squared_error: 0.2514\n",
            "Epoch 59/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2510 - mean_squared_error: 0.2510\n",
            "Epoch 60/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2478 - mean_squared_error: 0.2478\n",
            "Epoch 61/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2471 - mean_squared_error: 0.2471\n",
            "Epoch 62/80\n",
            "78836/78836 [==============================] - 35s 448us/step - loss: 0.2417 - mean_squared_error: 0.2417\n",
            "Epoch 63/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2410 - mean_squared_error: 0.2410\n",
            "Epoch 64/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2413 - mean_squared_error: 0.2413\n",
            "Epoch 65/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2402 - mean_squared_error: 0.2402\n",
            "Epoch 66/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2343 - mean_squared_error: 0.2343\n",
            "Epoch 67/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2355 - mean_squared_error: 0.2355\n",
            "Epoch 68/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2330 - mean_squared_error: 0.2330\n",
            "Epoch 69/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2310 - mean_squared_error: 0.2310\n",
            "Epoch 70/80\n",
            "78836/78836 [==============================] - 34s 431us/step - loss: 0.2274 - mean_squared_error: 0.2274\n",
            "Epoch 71/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2258 - mean_squared_error: 0.2258\n",
            "Epoch 72/80\n",
            "78836/78836 [==============================] - 34s 432us/step - loss: 0.2254 - mean_squared_error: 0.2254\n",
            "Epoch 73/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2259 - mean_squared_error: 0.2259\n",
            "Epoch 74/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2225 - mean_squared_error: 0.2225\n",
            "Epoch 75/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2228 - mean_squared_error: 0.2228\n",
            "Epoch 76/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2218 - mean_squared_error: 0.2218\n",
            "Epoch 77/80\n",
            "78836/78836 [==============================] - 34s 438us/step - loss: 0.2204 - mean_squared_error: 0.2204\n",
            "Epoch 78/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.2164 - mean_squared_error: 0.2164\n",
            "Epoch 79/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2128 - mean_squared_error: 0.2128\n",
            "Epoch 80/80\n",
            "78836/78836 [==============================] - 34s 433us/step - loss: 0.2221 - mean_squared_error: 0.2221\n",
            "model_3 saved\n",
            "Evaluate on test data by model 3\n",
            "19709/19709 [==============================] - 4s 223us/step\n",
            "test MSE loss is: [0.22135731976089354, 0.2213573157787323]\n",
            "test CI score is: 0.8298441026276207\n",
            "Epoch 1/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 2.1054 - mean_squared_error: 2.1054\n",
            "Epoch 2/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.6661 - mean_squared_error: 0.6661\n",
            "Epoch 3/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.5903 - mean_squared_error: 0.5903\n",
            "Epoch 4/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.5444 - mean_squared_error: 0.5444\n",
            "Epoch 5/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.5184 - mean_squared_error: 0.5184\n",
            "Epoch 6/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.5061 - mean_squared_error: 0.5061\n",
            "Epoch 7/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.4872 - mean_squared_error: 0.4872\n",
            "Epoch 8/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.4772 - mean_squared_error: 0.4772\n",
            "Epoch 9/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.4688 - mean_squared_error: 0.4689\n",
            "Epoch 10/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.4588 - mean_squared_error: 0.4588\n",
            "Epoch 11/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.4644 - mean_squared_error: 0.4644\n",
            "Epoch 12/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.4621 - mean_squared_error: 0.4621\n",
            "Epoch 13/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.4402 - mean_squared_error: 0.4402\n",
            "Epoch 14/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.4407 - mean_squared_error: 0.4407\n",
            "Epoch 15/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.4295 - mean_squared_error: 0.4295\n",
            "Epoch 16/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.4231 - mean_squared_error: 0.4231\n",
            "Epoch 17/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.4163 - mean_squared_error: 0.4163\n",
            "Epoch 18/80\n",
            "78836/78836 [==============================] - 39s 496us/step - loss: 0.4006 - mean_squared_error: 0.4006\n",
            "Epoch 19/80\n",
            "78836/78836 [==============================] - 36s 453us/step - loss: 0.4013 - mean_squared_error: 0.4013\n",
            "Epoch 20/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3918 - mean_squared_error: 0.3918\n",
            "Epoch 21/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3856 - mean_squared_error: 0.3856\n",
            "Epoch 22/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.3751 - mean_squared_error: 0.3751\n",
            "Epoch 23/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3653 - mean_squared_error: 0.3653\n",
            "Epoch 24/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3626 - mean_squared_error: 0.3626\n",
            "Epoch 25/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3541 - mean_squared_error: 0.3541\n",
            "Epoch 26/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3492 - mean_squared_error: 0.3492\n",
            "Epoch 27/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.3474 - mean_squared_error: 0.3474\n",
            "Epoch 28/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.3346 - mean_squared_error: 0.3346\n",
            "Epoch 29/80\n",
            "78836/78836 [==============================] - 34s 438us/step - loss: 0.3436 - mean_squared_error: 0.3436\n",
            "Epoch 30/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3297 - mean_squared_error: 0.3297\n",
            "Epoch 31/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3255 - mean_squared_error: 0.3255\n",
            "Epoch 32/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.3233 - mean_squared_error: 0.3233\n",
            "Epoch 33/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3174 - mean_squared_error: 0.3174\n",
            "Epoch 34/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.3129 - mean_squared_error: 0.3129\n",
            "Epoch 35/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.3095 - mean_squared_error: 0.3095\n",
            "Epoch 36/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3151 - mean_squared_error: 0.3151\n",
            "Epoch 37/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.3024 - mean_squared_error: 0.3024\n",
            "Epoch 38/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3006 - mean_squared_error: 0.3006\n",
            "Epoch 39/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2955 - mean_squared_error: 0.2955\n",
            "Epoch 40/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2925 - mean_squared_error: 0.2925\n",
            "Epoch 41/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2890 - mean_squared_error: 0.2890\n",
            "Epoch 42/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2872 - mean_squared_error: 0.2872\n",
            "Epoch 43/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2862 - mean_squared_error: 0.2862\n",
            "Epoch 44/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2850 - mean_squared_error: 0.2850\n",
            "Epoch 45/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2741 - mean_squared_error: 0.2741\n",
            "Epoch 46/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2754 - mean_squared_error: 0.2754\n",
            "Epoch 47/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2711 - mean_squared_error: 0.2711\n",
            "Epoch 48/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2629 - mean_squared_error: 0.2629\n",
            "Epoch 49/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2628 - mean_squared_error: 0.2628\n",
            "Epoch 50/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2597 - mean_squared_error: 0.2597\n",
            "Epoch 51/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2601 - mean_squared_error: 0.2601\n",
            "Epoch 52/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2593 - mean_squared_error: 0.2593\n",
            "Epoch 53/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2520 - mean_squared_error: 0.2520\n",
            "Epoch 54/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2494 - mean_squared_error: 0.2494\n",
            "Epoch 55/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2496 - mean_squared_error: 0.2496\n",
            "Epoch 56/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2445 - mean_squared_error: 0.2445\n",
            "Epoch 57/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2424 - mean_squared_error: 0.2424\n",
            "Epoch 58/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2421 - mean_squared_error: 0.2421\n",
            "Epoch 59/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2366 - mean_squared_error: 0.2366\n",
            "Epoch 60/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2368 - mean_squared_error: 0.2368\n",
            "Epoch 61/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2322 - mean_squared_error: 0.2322\n",
            "Epoch 62/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2322 - mean_squared_error: 0.2322\n",
            "Epoch 63/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2272 - mean_squared_error: 0.2272\n",
            "Epoch 64/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.2302 - mean_squared_error: 0.2302\n",
            "Epoch 65/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2251 - mean_squared_error: 0.2251\n",
            "Epoch 66/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2242 - mean_squared_error: 0.2242\n",
            "Epoch 67/80\n",
            "78836/78836 [==============================] - 35s 438us/step - loss: 0.2162 - mean_squared_error: 0.2162\n",
            "Epoch 68/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2165 - mean_squared_error: 0.2165\n",
            "Epoch 69/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2168 - mean_squared_error: 0.2168\n",
            "Epoch 70/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2105 - mean_squared_error: 0.2105\n",
            "Epoch 71/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2153 - mean_squared_error: 0.2153\n",
            "Epoch 72/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2106 - mean_squared_error: 0.2106\n",
            "Epoch 73/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2118 - mean_squared_error: 0.2118\n",
            "Epoch 74/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2083 - mean_squared_error: 0.2083\n",
            "Epoch 75/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.2046 - mean_squared_error: 0.2046\n",
            "Epoch 76/80\n",
            "78836/78836 [==============================] - 34s 437us/step - loss: 0.2038 - mean_squared_error: 0.2038\n",
            "Epoch 77/80\n",
            "78836/78836 [==============================] - 34s 435us/step - loss: 0.2013 - mean_squared_error: 0.2013\n",
            "Epoch 78/80\n",
            "78836/78836 [==============================] - 34s 434us/step - loss: 0.1984 - mean_squared_error: 0.1984\n",
            "Epoch 79/80\n",
            "78836/78836 [==============================] - 34s 436us/step - loss: 0.1993 - mean_squared_error: 0.1993\n",
            "Epoch 80/80\n",
            "78836/78836 [==============================] - 35s 439us/step - loss: 0.1960 - mean_squared_error: 0.1960\n",
            "model_4 saved\n",
            "Evaluate on test data by model 4\n",
            "19709/19709 [==============================] - 5s 231us/step\n",
            "test MSE loss is: [0.20769139244268642, 0.20769138634204865]\n",
            "test CI score is: 0.839162249985025\n",
            "Epoch 1/80\n",
            "78836/78836 [==============================] - 36s 453us/step - loss: 2.6636 - mean_squared_error: 2.6636\n",
            "Epoch 2/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.6957 - mean_squared_error: 0.6957\n",
            "Epoch 3/80\n",
            "78836/78836 [==============================] - 35s 448us/step - loss: 0.6067 - mean_squared_error: 0.6067\n",
            "Epoch 4/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 0.5486 - mean_squared_error: 0.5486\n",
            "Epoch 5/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.5090 - mean_squared_error: 0.5090\n",
            "Epoch 6/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.4979 - mean_squared_error: 0.4979\n",
            "Epoch 7/80\n",
            "78836/78836 [==============================] - 35s 448us/step - loss: 0.4783 - mean_squared_error: 0.4783\n",
            "Epoch 8/80\n",
            "78836/78836 [==============================] - 35s 450us/step - loss: 0.4604 - mean_squared_error: 0.4604\n",
            "Epoch 9/80\n",
            "78836/78836 [==============================] - 35s 450us/step - loss: 0.4681 - mean_squared_error: 0.4681\n",
            "Epoch 10/80\n",
            "78836/78836 [==============================] - 36s 458us/step - loss: 0.4439 - mean_squared_error: 0.4439\n",
            "Epoch 11/80\n",
            "78836/78836 [==============================] - 36s 458us/step - loss: 0.4331 - mean_squared_error: 0.4331\n",
            "Epoch 12/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 0.4373 - mean_squared_error: 0.4373\n",
            "Epoch 13/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 0.4210 - mean_squared_error: 0.4210\n",
            "Epoch 14/80\n",
            "78836/78836 [==============================] - 36s 460us/step - loss: 0.4178 - mean_squared_error: 0.4178\n",
            "Epoch 15/80\n",
            "78836/78836 [==============================] - 36s 453us/step - loss: 0.4146 - mean_squared_error: 0.4146\n",
            "Epoch 16/80\n",
            "78836/78836 [==============================] - 36s 455us/step - loss: 0.4129 - mean_squared_error: 0.4129\n",
            "Epoch 17/80\n",
            "78836/78836 [==============================] - 37s 470us/step - loss: 0.4082 - mean_squared_error: 0.4082\n",
            "Epoch 18/80\n",
            "78836/78836 [==============================] - 36s 452us/step - loss: 0.4009 - mean_squared_error: 0.4009\n",
            "Epoch 19/80\n",
            "78836/78836 [==============================] - 36s 453us/step - loss: 0.3933 - mean_squared_error: 0.3933\n",
            "Epoch 20/80\n",
            "78836/78836 [==============================] - 36s 454us/step - loss: 0.3903 - mean_squared_error: 0.3903\n",
            "Epoch 21/80\n",
            "78836/78836 [==============================] - 36s 455us/step - loss: 0.3842 - mean_squared_error: 0.3842\n",
            "Epoch 22/80\n",
            "78836/78836 [==============================] - 35s 448us/step - loss: 0.3851 - mean_squared_error: 0.3851\n",
            "Epoch 23/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.3749 - mean_squared_error: 0.3749\n",
            "Epoch 24/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.3709 - mean_squared_error: 0.3709\n",
            "Epoch 25/80\n",
            "78836/78836 [==============================] - 36s 451us/step - loss: 0.3698 - mean_squared_error: 0.3698\n",
            "Epoch 26/80\n",
            "78836/78836 [==============================] - 35s 450us/step - loss: 0.3597 - mean_squared_error: 0.3597\n",
            "Epoch 27/80\n",
            "78836/78836 [==============================] - 36s 455us/step - loss: 0.3683 - mean_squared_error: 0.3683\n",
            "Epoch 28/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.3610 - mean_squared_error: 0.3610\n",
            "Epoch 29/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.3449 - mean_squared_error: 0.3449\n",
            "Epoch 30/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3422 - mean_squared_error: 0.3422\n",
            "Epoch 31/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3445 - mean_squared_error: 0.3445\n",
            "Epoch 32/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3378 - mean_squared_error: 0.3378\n",
            "Epoch 33/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3262 - mean_squared_error: 0.3262\n",
            "Epoch 34/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.3291 - mean_squared_error: 0.3291\n",
            "Epoch 35/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3298 - mean_squared_error: 0.3298\n",
            "Epoch 36/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.3215 - mean_squared_error: 0.3215\n",
            "Epoch 37/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3146 - mean_squared_error: 0.3146\n",
            "Epoch 38/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.3109 - mean_squared_error: 0.3109\n",
            "Epoch 39/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.3109 - mean_squared_error: 0.3109\n",
            "Epoch 40/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.3076 - mean_squared_error: 0.3076\n",
            "Epoch 41/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.3011 - mean_squared_error: 0.3011\n",
            "Epoch 42/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2986 - mean_squared_error: 0.2986\n",
            "Epoch 43/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2957 - mean_squared_error: 0.2957\n",
            "Epoch 44/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2986 - mean_squared_error: 0.2986\n",
            "Epoch 45/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2875 - mean_squared_error: 0.2875\n",
            "Epoch 46/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2959 - mean_squared_error: 0.2959\n",
            "Epoch 47/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.2848 - mean_squared_error: 0.2848\n",
            "Epoch 48/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2806 - mean_squared_error: 0.2806\n",
            "Epoch 49/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2777 - mean_squared_error: 0.2777\n",
            "Epoch 50/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2723 - mean_squared_error: 0.2723\n",
            "Epoch 51/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2688 - mean_squared_error: 0.2688\n",
            "Epoch 52/80\n",
            "78836/78836 [==============================] - 35s 440us/step - loss: 0.2663 - mean_squared_error: 0.2663\n",
            "Epoch 53/80\n",
            "78836/78836 [==============================] - 35s 441us/step - loss: 0.2673 - mean_squared_error: 0.2673\n",
            "Epoch 54/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2622 - mean_squared_error: 0.2622\n",
            "Epoch 55/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2585 - mean_squared_error: 0.2585\n",
            "Epoch 56/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2609 - mean_squared_error: 0.2609\n",
            "Epoch 57/80\n",
            "78836/78836 [==============================] - 35s 442us/step - loss: 0.2591 - mean_squared_error: 0.2591\n",
            "Epoch 58/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2531 - mean_squared_error: 0.2531\n",
            "Epoch 59/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2478 - mean_squared_error: 0.2478\n",
            "Epoch 60/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.2477 - mean_squared_error: 0.2477\n",
            "Epoch 61/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2458 - mean_squared_error: 0.2458\n",
            "Epoch 62/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.2429 - mean_squared_error: 0.2429\n",
            "Epoch 63/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2426 - mean_squared_error: 0.2426\n",
            "Epoch 64/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2410 - mean_squared_error: 0.2410\n",
            "Epoch 65/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.2401 - mean_squared_error: 0.2401\n",
            "Epoch 66/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.2354 - mean_squared_error: 0.2354\n",
            "Epoch 67/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2343 - mean_squared_error: 0.2343\n",
            "Epoch 68/80\n",
            "78836/78836 [==============================] - 35s 449us/step - loss: 0.2312 - mean_squared_error: 0.2312\n",
            "Epoch 69/80\n",
            "78836/78836 [==============================] - 35s 447us/step - loss: 0.2267 - mean_squared_error: 0.2267\n",
            "Epoch 70/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2278 - mean_squared_error: 0.2278\n",
            "Epoch 71/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2294 - mean_squared_error: 0.2294\n",
            "Epoch 72/80\n",
            "78836/78836 [==============================] - 35s 443us/step - loss: 0.2243 - mean_squared_error: 0.2243\n",
            "Epoch 73/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2209 - mean_squared_error: 0.2209\n",
            "Epoch 74/80\n",
            "78836/78836 [==============================] - 35s 445us/step - loss: 0.2195 - mean_squared_error: 0.2195\n",
            "Epoch 75/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2219 - mean_squared_error: 0.2219\n",
            "Epoch 76/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2148 - mean_squared_error: 0.2148\n",
            "Epoch 77/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2127 - mean_squared_error: 0.2127\n",
            "Epoch 78/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2122 - mean_squared_error: 0.2122\n",
            "Epoch 79/80\n",
            "78836/78836 [==============================] - 35s 446us/step - loss: 0.2141 - mean_squared_error: 0.2141\n",
            "Epoch 80/80\n",
            "78836/78836 [==============================] - 35s 444us/step - loss: 0.2116 - mean_squared_error: 0.2116\n",
            "model_5 saved\n",
            "Evaluate on test data by model 5\n",
            "19709/19709 [==============================] - 5s 253us/step\n",
            "test MSE loss is: [0.21532028434005487, 0.21532033383846283]\n",
            "test CI score is: 0.8317062154974488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0UadAx-WImv",
        "outputId": "9ed5f4e9-7eb0-4dc8-9a9d-bf90b43a31c9"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "save_folder = f'{G_PATH}/saved_results/'\n",
        "with open(save_folder + \"cv_mse.txt\", \"rb\") as f:\n",
        "  cv_mse = pickle.load(f)\n",
        "with open(save_folder + \"MSE.txt\", \"rb\") as f:\n",
        "  MSE = pickle.load(f)\n",
        "with open(save_folder + \"CI.txt\", \"rb\") as f:\n",
        "  cis = pickle.load(f)\n",
        "print(\"test MSE loss is:\", np.mean(MSE))\n",
        "print('test CI score is:', np.mean(cis))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test MSE loss is: 0.21358680427074433\n",
            "test CI score is: 0.8337713494290373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wUSxsUZzJ82"
      },
      "source": [
        "#### (5) Result\n",
        "The CNN model with cross validation gives almost same MSE and CI score on the test set as the original CNN model. The reason may be that CNN already extracts the characteristics of drugs and proteins very well, so there is not much improvement that cross validation can do. \n",
        "\n",
        "Considering that cross validation takes long training time, we recommend using CNN model without cross validation in practice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my0BqyOkSFYa"
      },
      "source": [
        "## 4. Use  your model on COVID-19 protease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkmmMhjOSFYc"
      },
      "source": [
        "Now, use your trained model to identify drugs that could be used as COVID-19 protease inhibitors from these 2111 drugs in the dataset. The sequence of the protease is provided in `6Y84_A.fasta.txt`. You might want to first predict a binding affinity of Ritonavior, a well known HIV drug that binds to HIV protease, to get the sense of a good binding score for this task. SMILES of Ritonavior is provided below.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "DFt_emuuSFYd",
        "outputId": "e2ace5a8-de13-41ec-c9fe-4500dbfcf382"
      },
      "source": [
        "ritonavior = 'CC(C)C1=NC(=CS1)CN(C)C(=O)NC(C(C)C)C(=O)NC(CC2=CC=CC=C2)CC(C(CC3=CC=CC=C3)NC(=O)OCC4=CN=CS4)O'\n",
        "rit_mol = MolFromSmiles(ritonavior)\n",
        "Draw.MolToImage(rit_mol)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x7F635521F510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6qBMNh9iWJW",
        "outputId": "b70a991d-ad28-487c-87b4-2dea767a1426"
      },
      "source": [
        "rit = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(ritonavior),isomericSmiles=True)])\n",
        "rit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CC(C)c1nc(CN(C)C(=O)NC(C(=O)NC(Cc2ccccc2)CC(O)C(Cc2ccccc2)NC(=O)OCc2cncs2)C(C)C)cs1'],\n",
              "      dtype='<U83')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2meDhKVKSFYi"
      },
      "source": [
        "Please keep in mind that proteins in KIBA data are kinase family, a different kind from protease. So in this exercise, we are relying on transfer learning. That is, the learned embedding for predicting kinase could be useful for predicting protease binding as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaIxPjyUdrCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4411e37-29d5-47e6-d113-711db3d2f121"
      },
      "source": [
        "protease = \"SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQ\"\n",
        "protease_tr = np.array([seq_to_cat(protease)])\n",
        "protease_tr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.,  6.,  5., 16.,  9., 11.,  0.,  5., 14., 17.,  6.,  9., 20.,\n",
              "         4.,  6.,  2., 11., 20., 15., 20., 18.,  2.,  6., 18., 18., 18.,\n",
              "        10., 12.,  6., 10., 21., 10.,  3.,  3., 20., 20., 23.,  2., 14.,\n",
              "        16.,  7., 20.,  8.,  2., 18., 17.,  4.,  3., 11., 10., 12., 14.,\n",
              "        12., 23.,  4.,  3., 10., 10.,  8., 16.,  9., 17., 12.,  7., 12.,\n",
              "         5., 10., 20., 15.,  0.,  6., 12., 20., 15., 10., 16., 20.,  8.,\n",
              "         6.,  7., 17., 11., 15., 12.,  2., 20., 10.,  9., 10.,  9., 20.,\n",
              "         3., 18.,  0., 12., 14.,  9., 18., 14.,  9., 23.,  9.,  5., 20.,\n",
              "        16.,  8., 15., 14.,  6., 15., 18.,  5., 17., 20., 10.,  0.,  2.,\n",
              "        23., 12.,  6., 17., 14., 17.,  6., 20., 23., 15.,  2.,  0., 11.,\n",
              "        16., 14., 12.,  5., 18.,  8.,  9.,  6., 17.,  5., 10., 12.,  6.,\n",
              "        17.,  2.,  6., 17., 20.,  6.,  5., 12.,  8.,  3., 23.,  3.,  2.,\n",
              "        20., 17.,  5.,  2., 23., 11.,  7.,  7., 11.,  4., 10., 14., 18.,\n",
              "         6., 20.,  7.,  0.,  6., 18.,  3., 10.,  4.,  6., 12.,  5., 23.,\n",
              "         6., 14.,  5., 20.,  3., 16., 15., 18.,  0., 15.,  0.,  0.,  6.,\n",
              "        18.,  3., 18., 18.,  8., 18., 20., 12., 20., 10.,  0., 21., 10.,\n",
              "        23.,  0.,  0., 20.,  8., 12.,  6.,  3., 16., 21.,  5., 10., 12.,\n",
              "        16.,  5., 18., 18., 18., 10., 12.,  3.,  5., 12., 10., 20.,  0.,\n",
              "        11.,  9., 23., 12., 23.,  4., 14., 10., 18., 15.,  3.,  7., 20.,\n",
              "         3.,  8., 10.,  6., 14., 10., 17.,  0., 15., 18.,  6.,  8.,  0.,\n",
              "        20., 10.,  3., 11.,  2.,  0., 17., 10.,  9.,  4., 10., 10., 15.,\n",
              "        12.,  6., 11., 12.,  6., 16., 18.,  8., 10.,  6., 17.,  0., 10.,\n",
              "        10.,  4.,  3.,  4.,  5., 18., 14.,  5.,  3., 20., 20., 16., 15.,\n",
              "         2., 17.,  6., 20., 18.,  5., 15.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDP2vcT_lz87",
        "outputId": "3ee4135d-a566-4b9f-a234-b608678f0ecd"
      },
      "source": [
        "smileToMol = lambda x: MolFromSmiles(x)\n",
        "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
        "\n",
        "rit_mol = list(map(smileToMol, rit))\n",
        "rit_ecfp = featurizer.featurize(rit_mol)\n",
        "\n",
        "print(rit_ecfp.shape, protease_tr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024) (1, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7umG2xdv-uu"
      },
      "source": [
        "### Prediction by the baseline model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRd6CYBhe_-U",
        "outputId": "19f92ca8-f322-4c10-9fea-e36b897b1754"
      },
      "source": [
        "path = './drive/MyDrive/Colab Notebooks/data_Drug_target_binding_affinity/baseline_model'\n",
        "model = tf.keras.models.load_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEbivBVBg0GY",
        "outputId": "471ae69a-ab49-458d-97b5-72152d2656c4"
      },
      "source": [
        "# Have fun!\n",
        "for layer in model.layers[:5]:\n",
        "  layer.trainable = \"False\"\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "dense_113_input (InputLayer)    [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_114_input (InputLayer)    [(None, 1000)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_113 (Dense)               (None, 1)            1025        dense_113_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_114 (Dense)               (None, 1)            1001        dense_114_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 2)            0           dense_113[0][0]                  \n",
            "                                                                 dense_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_115 (Dense)               (None, 1024)         3072        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 1024)         0           dense_115[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_116 (Dense)               (None, 1024)         1049600     dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 1024)         0           dense_116[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_117 (Dense)               (None, 512)          524800      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_118 (Dense)               (None, 1)            513         dense_117[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,580,011\n",
            "Trainable params: 1,580,011\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEvhGQS6k6jL",
        "outputId": "66741c75-e537-4735-aac1-3e8000a0b73c"
      },
      "source": [
        "target = model.predict([rit_ecfp, protease_tr])[0][0]\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.488001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IakEO6ORlVrp",
        "outputId": "83ffd58b-3ab8-4e6c-ed2c-e915d6336efc"
      },
      "source": [
        "pred_drug = ritonavior\n",
        "smileToMol = lambda x: MolFromSmiles(x)\n",
        "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
        "for drug in drugs:\n",
        "  drug_smiles = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(drug),isomericSmiles=True)])\n",
        "  drug_mol = list(map(smileToMol, drug_smiles))\n",
        "  drug_ecfp = featurizer.featurize(drug_mol)\n",
        "  score = model.predict([drug_ecfp, protease_tr])[0][0]\n",
        "  if score>target:\n",
        "    print(drug, score)\n",
        "    target = score\n",
        "    pred_drug = drug\n",
        "print(pred_drug, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O=C(Cc1ccccc1)Nc1cccc(-c2nc3sccn3c2-c2ccnc(Nc3cccc(N4CCOCC4)c3)n2)c1 11.586634\n",
            "CNc1cncc(-c2c[nH]c(=O)c(NC(=O)c3ccc(N4CCCC4CN4CCCC4)cc3)c2)n1 11.786759\n",
            "CN(c1ncccc1CNc1nc(Nc2ccc3c(c2)CC(=O)N3)ncc1C(F)(F)F)S(C)(=O)=O 12.052496\n",
            "COc1cc(Nc2ncc([N+](=O)[O-])c(Nc3ccccc3C(N)=O)n2)cc(OC)c1OC 12.538106\n",
            "CN(C)C1CCCC(Nc2nc(Cl)cc(-c3c[nH]c4ncccc34)n2)C1 12.572794\n",
            "FC(F)(F)c1cccc(CNc2cc(-c3c[nH]c4ncccc34)ncn2)c1 12.776003\n",
            "Clc1cc(-c2c[nH]c3ncccc23)nc(NC2CCOCC2)n1 12.80786\n",
            "Cn1cc(Nc2ncc(Cl)c(Nc3ccccc3C(N)=O)n2)cn1 12.933596\n",
            "CCNC(=O)NC1CCC(Nc2nc(Cl)cc(-c3c[nH]c4ncccc34)n2)CC1 13.015325\n",
            "Cn1cc(Nc2ncc(Br)c(Nc3ccccc3C(N)=O)n2)cn1 13.150837\n",
            "CNCC(=O)NC1CCC(Nc2nc(Cl)cc(-c3c[nH]c4ncccc34)n2)CC1 13.20871\n",
            "CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6ccccc6n2c5c31)C(=O)NC4 13.486596\n",
            "Cc1cc(O)cc2oc(=O)c3c(O)cc(OS(=O)(=O)O)cc3c12 13.762829\n",
            "CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6cc(O)ccc6n2c5c31)C(=O)NC4 14.24049\n",
            "CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6cc(O)ccc6n2c5c31)C(=O)NC4 14.24049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "LqnM86wz7aWC",
        "outputId": "3dcf1733-0420-40f6-8e31-6a0866fc7812"
      },
      "source": [
        "best_mol = MolFromSmiles(\"CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6cc(O)ccc6n2c5c31)C(=O)NC4\")\n",
        "Draw.MolToImage(best_mol)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x7F63551E8E90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQDepkQiwVbI"
      },
      "source": [
        "The drug with the highest binding affinity is CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6cc(O)ccc6n2c5c31)C(=O)NC4. And the affinity of this drug to the COVID-19 protease is $14.24049$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjhkWijVwOGv"
      },
      "source": [
        "### Prediction by the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf2adYa8tzve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a3664c-4481-4dc1-d34b-21426f54de10"
      },
      "source": [
        "num_train, num_drugs = rit_ecfp.shape\n",
        "num_prot = protease_tr.shape[1]\n",
        "rit_ecfp = rit_ecfp.reshape((num_train, num_drugs, 1))\n",
        "protease_tr_reshape = protease_tr.reshape((num_train, num_prot, 1))\n",
        "print(rit_ecfp.shape, protease_tr_reshape.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024, 1) (1, 1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUMN8FjavXQl",
        "outputId": "357839c3-8d95-4650-d596-7a7aa14e2b22"
      },
      "source": [
        "path = './drive/MyDrive/Colab Notebooks/data_Drug_target_binding_affinity/cnn_model'\n",
        "model = tf.keras.models.load_model(path)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv1d_3_input (InputLayer)     [(None, 1024, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4_input (InputLayer)     [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 1022, 16)     64          conv1d_3_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 998, 16)      64          conv1d_4_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 340, 16)      0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 332, 16)      0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 5440)         0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 5312)         0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 5440)         0           flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 5312)         0           flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           87056       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           85008       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32)           0           dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1024)         33792       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 16)           16400       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            17          dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 222,401\n",
            "Trainable params: 222,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMV0yHpZwShF",
        "outputId": "d5a7abe6-c42a-4771-ffb6-469002864dbe"
      },
      "source": [
        "target = model.predict([rit_ecfp, protease_tr_reshape])[0][0]\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.476215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBAmri5swMFi",
        "outputId": "c9a7f708-2a4c-4442-c548-c432480b5fca"
      },
      "source": [
        "pred_drug = ritonavior\n",
        "smileToMol = lambda x: MolFromSmiles(x)\n",
        "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
        "for drug in drugs:\n",
        "  drug_smiles = np.array([Chem.MolToSmiles(Chem.MolFromSmiles(drug),isomericSmiles=True)])\n",
        "  drug_mol = list(map(smileToMol, drug_smiles))\n",
        "  drug_ecfp = featurizer.featurize(drug_mol)\n",
        "  drug_ecfp = drug_ecfp.reshape((num_train, num_drugs, 1))\n",
        "  score = model.predict([drug_ecfp, protease_tr_reshape])[0][0]\n",
        "  if score>target:\n",
        "    print(drug, score)\n",
        "    target = score\n",
        "    pred_drug = drug\n",
        "print(pred_drug, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COc1cc(Nc2ncc([N+](=O)[O-])c(Nc3ccccc3C(N)=O)n2)cc(OC)c1OC 12.898549\n",
            "Cc1[nH]nc2ccc(-c3cncc(OCC(N)Cc4cccc(OC(F)(F)F)c4)c3)cc12 13.369903\n",
            "Cc1[nH]nc2ccc(-c3cncc(OCC(N)Cc4cccc(Cl)c4)c3)cc12 13.8015175\n",
            "Cc1[nH]nc2ccc(-c3cncc(OCC(N)Cc4ccc(Cl)c(Cl)c4)c3)cc12 13.81483\n",
            "Cn1cc(Nc2ncc(Br)c(Nc3ccccc3C(N)=O)n2)cn1 13.887487\n",
            "CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6ccccc6n2c5c31)C(=O)NC4 14.350755\n",
            "COc1cc(O)c2c(c1)C1(OC2=O)C(C)=CC(=O)C1O 14.415564\n",
            "COc1cc(O)c2c(c1)C(=O)c1cc(C)c(O)cc1C2=O 14.471263\n",
            "Cc1cc(O)cc2oc(=O)c3c(O)cc(OS(=O)(=O)O)cc3c12 14.578851\n",
            "COc1cc(O)c2c(=O)oc3cc(O)cc(C)c3c2c1 14.655168\n",
            "COc1cc(O)c2c(=O)oc3c(O)c(O)cc(C)c3c2c1 14.964367\n",
            "COc1cc(O)c2c(=O)oc3c(O)c(O)cc(C)c3c2c1 14.964367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "U80-nZ257TE8",
        "outputId": "8ed3148c-36c9-477d-95e1-f842df5af088"
      },
      "source": [
        "best_mol = MolFromSmiles(\"COc1cc(O)c2c(=O)oc3c(O)c(O)cc(C)c3c2c1\")\n",
        "Draw.MolToImage(best_mol)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x7F6355282490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvBaoWh36zXZ"
      },
      "source": [
        "When using pretrained CNN model, The drug with the highest binding affinity is COc1cc(O)c2c(=O)oc3c(O)c(O)cc(C)c3c2c1. And the affinity of this drug to the COVID-19 protease is $14.96436$. The result is different from the baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXO7dROiwYCh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}